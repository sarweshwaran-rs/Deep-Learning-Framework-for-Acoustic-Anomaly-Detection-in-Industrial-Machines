{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bda58e11",
   "metadata": {},
   "source": [
    "Necessary Standard Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f73ee97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter, defaultdict\n",
    "from torch.utils.data import DataLoader, Subset, WeightedRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, balanced_accuracy_score, roc_curve, auc, f1_score, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996d091b",
   "metadata": {},
   "source": [
    "Importing the Custom "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12d71e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_modules_path = os.path.abspath(r'F:\\Capstone\\DFCA')\n",
    "\n",
    "# Add the path to sys.path\n",
    "if custom_modules_path not in sys.path:\n",
    "    sys.path.append(custom_modules_path)\n",
    "\n",
    "from scripts.pretrain_pipeline import FusedModel\n",
    "from utils.augmentations import ComposeT, ToTensor, SpecTimePitchWarp, SpecAugment, GradCAM\n",
    "from models.heads import AnomalyScorer, SimpleAnomalyMLP, EmbeddingMLP,ComplexAnomalyMLP\n",
    "from models.losses import ContrastiveLoss\n",
    "from utils.datasets import PairedSpectrogramDataset, PairedSpectrogramDatasetCS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc1b470",
   "metadata": {},
   "source": [
    "Metrics and GradCam Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c18967f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pAUC(labels, preds, max_fpr = 0.1):\n",
    "    \"\"\"\n",
    "    Calculates Partial AUC (pAUC) for a given FPR range.\n",
    "    Args:\n",
    "        labels (array): True binary labels.\n",
    "        preds (array): Predicted probabilities for the positive class.\n",
    "        max_fpr (float): Maximum False Positive Rate for pAUC calculation.\n",
    "    Returns:\n",
    "        float: pAUC score.\n",
    "    \"\"\"\n",
    "    if len(np.unique(labels)) < 2:\n",
    "        return float('nan')\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(labels, preds)\n",
    "    #filter for FPR <= max_fpr\n",
    "    mask = fpr <= max_fpr\n",
    "    fpr_filtered, tpr_filtered = fpr[mask], tpr[mask] \n",
    "      \n",
    "    if fpr_filtered.size == 0:\n",
    "        return 0.0\n",
    "\n",
    "    if fpr_filtered.max() < max_fpr:\n",
    "        idx = np.where(fpr <= max_fpr)[0][-1]\n",
    "        if idx + 1 < len(fpr):\n",
    "            x1, y1 = fpr[idx], tpr[idx]\n",
    "            x2, y2 = fpr[idx + 1], tpr[idx + 1]\n",
    "            tpr_interp = y1 + (y2 - y1) * (max_fpr - x1) / (x2 - x1) if (x2 - x1) > 0 else y1\n",
    "            fpr_filtered = np.append(fpr_filtered, max_fpr)\n",
    "            tpr_filtered = np.append(tpr_filtered, tpr_interp)\n",
    "            sort_idx = np.argsort(fpr_filtered)\n",
    "            fpr_filtered = fpr_filtered[sort_idx]\n",
    "            tpr_filtered = tpr_filtered[sort_idx]\n",
    "\n",
    "    return auc(fpr_filtered, tpr_filtered) / max_fpr if len(fpr_filtered) >= 2 else 0.0\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, labels, save_path, title=\"Confusion Matrix\"):\n",
    "    \"\"\"\n",
    "        Plots a confusion matrix for model evaluation\n",
    "    Args:\n",
    "        y_true (list or np.array): Ground truth labels.\n",
    "        y_pred (list or np.array): Predicted labels.\n",
    "        labels (list): A list of labels for the matrix axes (['Normal', 'Abnormal'])\n",
    "        title (str): Title for the plot\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp+fn) if (tp + fn) > 0 else 0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "\n",
    "    print(f\"TP: {tp} | TN: {tn} | FP: {fp} | FN: {fn} | Precision: {precision:.4f} | Recall: {recall:.4f} | Specificity: {specificity:.4f}\")\n",
    "    plt.figure(figsize=(8,8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title(title)\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    plt.savefig(os.path.join(save_path, \"Confusion Matrix.png\"))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "def find_last_conv(module, name_contains=None):\n",
    "    \"\"\"\n",
    "    Returns (module_ref, full_name) of the last nn.Conv2d found in module.\n",
    "    If name_contains is provided, prefer conv modules whose name includes that substring.\n",
    "    \"\"\"\n",
    "    last = (None, None)\n",
    "    for n,m in module.named_modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            last = (m,n)\n",
    "        \n",
    "    if name_contains:\n",
    "        # Try to find last conv with name containing substring\n",
    "        cand = (None, None)\n",
    "        for n, m in module.named_modules():\n",
    "            if isinstance(m,nn.Conv2d) and name_contains in n.lower():\n",
    "                cand = (m,n)\n",
    "        \n",
    "        if cand[0] is not None:\n",
    "            return cand\n",
    "    \n",
    "    return last\n",
    "\n",
    "# -------------------------------\n",
    "# GradCAM Utilities\n",
    "# -------------------------------\n",
    "def prepare_gradcam_targets(model, device):\n",
    "    \"\"\"\n",
    "    Heuristic: try to find conv layers for stft and cqt branches by name\n",
    "    Fallback: the last conv in the model\n",
    "    Return dict {'stft':module, 'cqt':module}\n",
    "    \"\"\"\n",
    "    targets = {}\n",
    "    stft_conv = find_last_conv(model, name_contains='stft')\n",
    "    cqt_conv = find_last_conv(model, name_contains='cqt')\n",
    "\n",
    "    if stft_conv[0] is None:\n",
    "        stft_conv = find_last_conv(model, name_contains=None)\n",
    "    if cqt_conv[0] is None:\n",
    "        cqt_conv = find_last_conv(model, name_contains=None)\n",
    "    \n",
    "    targets['stft'] = stft_conv[0]\n",
    "    targets['cqt'] = cqt_conv[0]\n",
    "    \n",
    "    return targets\n",
    "\n",
    "def build_gradcam_for_model(model, device):\n",
    "    targets = prepare_gradcam_targets(model, device)\n",
    "    cams = {}\n",
    "    if targets['stft'] is not None:\n",
    "        cams['stft'] = GradCAM(model, targets['stft'])\n",
    "    if targets['cqt'] is not None:\n",
    "        cams['cqt'] = GradCAM(model, targets['cqt'])\n",
    "    return cams\n",
    "\n",
    "def run_and_save_gradcams(model, cams, dataset, device, out_dir=\"gradcam_outputs\", n_samples=8):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    model.eval()\n",
    "    saved = 0\n",
    "    for i in range(len(dataset)):\n",
    "        item = dataset[i]\n",
    "        stft = item['stft'].unsqueeze(0).to(device)\n",
    "        cqt = item['cqt'].unsqueeze(0).to(device)\n",
    "        label = int(item['label'])\n",
    "\n",
    "        #forward pass to get logtis\n",
    "        logits = model(stft, cqt)\n",
    "        #Pick scalar to backprop\n",
    "        if logits.ndim == 2 and logits.shape[1] == 2:\n",
    "            target_score = logits[:,1].squeeze()\n",
    "        else:\n",
    "            if logits.ndim == 2 and logits.shape[1] == 1:\n",
    "                target_score = logits.squeeze(1)\n",
    "            else:\n",
    "                target_score = logits\n",
    "        \n",
    "        #stft gradcam\n",
    "        for branch, cam in cams.items():\n",
    "            try:\n",
    "                scalar = target_score.sum()\n",
    "                heat = cam.heatmap(stft if branch =='stft' else cqt, scalar, device)\n",
    "            except Exception as e:\n",
    "                print(f\"GradCAM failed for sample {i} branch {branch}: {e}\")\n",
    "                heat = None\n",
    "            \n",
    "            # save overlay\n",
    "            base = (stft.squeeze(0).cpu().numpy() if branch =='stft' else cqt.squeeze(0).cpu().numpy())\n",
    "            if base.ndim == 3:\n",
    "                base_img = base[0]\n",
    "            else:\n",
    "                base_img = base\n",
    "            \n",
    "            # normalize base_img to 0..1\n",
    "            base_img = base_img - base_img.min()\n",
    "            if base_img.max() > 0:\n",
    "                base_img = base_img / base_img.max()\n",
    "            # Save figure\n",
    "            plt.figure(figsize=(6,4))\n",
    "            plt.imshow(base_img, aspect='auto', origin='lower')\n",
    "            if heat is not None:\n",
    "                cmap = plt.get_cmap('jet')\n",
    "                heat_resized = np.flipud(heat)\n",
    "                plt.imshow(heat_resized, cmap=cmap, alpha=0.5, extent=(0,base_img.shape[1], 0, base_img.shape[0]))\n",
    "            plt.title(f\"GradCAM {branch.upper()} - label:{label} idx:{i}\")\n",
    "            fname = os.path.join(out_dir, f\"gradcam_{branch}_idx_{i}_label{label}.png\")\n",
    "            plt.colorbar()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(fname)\n",
    "            plt.close()\n",
    "        saved +=1\n",
    "        if saved >= n_samples:\n",
    "            break\n",
    "\n",
    "    # remove hooks\n",
    "    for cam in cams.values():\n",
    "        cam.remove_hooks()\n",
    "    print(f\"Saved {saved} GradCAM images to {out_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec54f2b",
   "metadata": {},
   "source": [
    "Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3cbb12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cuda - NVIDIA GeForce MX450\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using Device: {device} - {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "FEATURES_DIR = os.path.abspath(r'F:\\Capstone\\DFCA\\data\\features')\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 50\n",
    "LR = 5e-5\n",
    "WEIGHT_DECAY = 1e-2\n",
    "CHECKPOINT_DIR = os.path.abspath(r'F:\\Capstone\\DFCA\\checkpoints')\n",
    "CONTRASTIVE_MARGIN = 0.5\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "HEAD_MODE = 'mlp'\n",
    "EMB_DIM = 64\n",
    "\n",
    "save_path = os.path.join(CHECKPOINT_DIR,'DFCA', '[Anomaly-With-Transformations-dropout=0.4]_MLP(5e-5)','ComplexMLP-75')\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789b63b5",
   "metadata": {},
   "source": [
    "Train & Evaluate Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a27f8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader, criterion, phase=\"Evaluation\", device=device, head_mode='classifier', sample_count=10, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Evaluate a model on a given dataset.\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model to evaluate.\n",
    "        data_loader: DataLoader for the dataset to evaluate on.\n",
    "        criterion: Loss function.\n",
    "        phase (str): Label for the evaluation phase (e.g., \"Train\", \"Validation\", \"Test\").\n",
    "        device: Torch device ('cuda' or 'cpu').\n",
    "        head_mode (str): Type of model head ('classifier', 'mlp', 'prototype', 'embedding').\n",
    "        sample_count (int): Number of sample predictions to print for inspection.\n",
    "        threshold (float): The classification threshold to use for binary predictions.\n",
    "\n",
    "    Returns:\n",
    "        avg_loss: Average loss over the dataset.\n",
    "        auc_score: ROC AUC score.\n",
    "        acc_score: Accuracy.\n",
    "        bacc_score: Balanced accuracy.\n",
    "        f1_score: F1-score.\n",
    "        all_labels: List of all ground truth labels.\n",
    "        all_probs: List of all predicted probabilities/scores for the positive class.\n",
    "        best_threshold: The optimal threshold found, or the provided threshold.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_labels, all_probs = [], []\n",
    "    \n",
    "    best_threshold = threshold\n",
    "    f1 = 0.0\n",
    "    # [DEBUG]\n",
    "    class_counts = {0: 0, 1: 0}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=phase):\n",
    "            stft = batch['stft'].to(device)\n",
    "            cqt = batch['cqt'].to(device)\n",
    "            labels = batch['label'].to(device).long()\n",
    "            \n",
    "            for lbl in labels.cpu().numpy():\n",
    "                class_counts[int(lbl)] += 1\n",
    "            \n",
    "            loss = None\n",
    "            if head_mode == \"prototype\":\n",
    "                embeddings, prototype = model(stft, cqt)\n",
    "                embeddings = F.normalize(embeddings, dim=1)\n",
    "                prototype = F.normalize(prototype, dim=0)\n",
    "                if prototype.dim() == 1:\n",
    "                    prototype = prototype.unsqueeze(0)\n",
    "                prototype = prototype.expand_as(embeddings)\n",
    "                cos_sim = torch.sum(embeddings * prototype, dim=1)\n",
    "                probs = 1 - cos_sim\n",
    "                loss = criterion(embeddings, prototype, labels.float())\n",
    "            \n",
    "            elif head_mode in [\"classifier\", \"mlp\"]:\n",
    "                logits = model(stft, cqt)\n",
    "                if logits.ndim == 2 and logits.shape[1] == 2:\n",
    "                    probs = torch.softmax(logits, dim=1)[:, 1]\n",
    "                    loss = criterion(logits, labels.long())\n",
    "                else:\n",
    "                    if logits.ndim == 2 and logits.shape[1] == 1:\n",
    "                        logits = logits.squeeze(1)\n",
    "                    probs = torch.sigmoid(logits)\n",
    "                    loss = criterion(logits, labels.float())\n",
    "            \n",
    "            elif head_mode == \"embedding\":\n",
    "                embeddings = model(stft, cqt)\n",
    "                normal_proto = model.head.normal_prototype\n",
    "                embeddings = F.normalize(embeddings, dim=1)\n",
    "                normal_proto = F.normalize(normal_proto, dim=0)\n",
    "                cos_sim = torch.sum(embeddings * normal_proto.unsqueeze(0).expand_as(embeddings), dim=1)\n",
    "                probs = 1 - cos_sim\n",
    "                if isinstance(criterion, ContrastiveLoss):\n",
    "                    loss = criterion(embeddings, normal_proto, labels)\n",
    "                else:\n",
    "                    loss = criterion(probs, labels.float())\n",
    "            elif head_mode == 'classifier-1':\n",
    "                logits = model(stft,cqt)\n",
    "                if logits.ndim == 2 and logits.shape[1] ==1:\n",
    "                    logits = logits.squeeze(1)\n",
    "                probs = torch.sigmoid(logits)\n",
    "                loss = criterion(logits, labels.float())\n",
    "            \n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported head_mode:{head_mode}\")\n",
    "            \n",
    "            running_loss += loss.item() * stft.size(0)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    \n",
    "    print(f\"[DEBUG] {phase} label counts: {class_counts}\")\n",
    "    \n",
    "    # Logic for finding optimal threshold on Validation set\n",
    "    f1 = 0.0 # Initialize f1\n",
    "    if phase == \"Validation\":\n",
    "        best_f1 = 0\n",
    "        current_optimal_threshold = 0.5\n",
    "        for thresh in np.arange(0.01, 1.0, 0.01):\n",
    "            predictions_thresh = (np.array(all_probs) > thresh).astype(int)\n",
    "            f1_candidate = f1_score(all_labels, predictions_thresh)\n",
    "            if f1_candidate > best_f1:\n",
    "                best_f1 = f1_candidate\n",
    "                current_optimal_threshold = thresh\n",
    "\n",
    "        best_threshold = current_optimal_threshold\n",
    "        f1 = best_f1\n",
    "        print(f\"Optimal Threshold (F1-score): {best_threshold:.2f}\")\n",
    "        print(f\"Best F1-score on Validation Set: {best_f1:.4f}\")\n",
    "    \n",
    "    # Calculate all metrics using the selected or optimal threshold\n",
    "    all_preds = (np.array(all_probs) > best_threshold).astype(int)\n",
    "    if phase != \"Validation\":\n",
    "        if len(np.unique(all_labels)) > 1:\n",
    "            f1 = f1_score(all_labels, all_preds)\n",
    "        else:\n",
    "            f1 = 0.0\n",
    "    \n",
    "    avg_loss = running_loss / len(data_loader.dataset)\n",
    "    auc_score = roc_auc_score(all_labels, all_probs) if len(np.unique(all_labels)) > 1 else float('nan')\n",
    "    acc_score = accuracy_score(all_labels, all_preds)\n",
    "    bacc_score = balanced_accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    print(f\"{phase} Loss: {avg_loss:.4f}, {phase} AUC: {auc_score:.4f}, {phase} ACC: {acc_score:.4f}, {phase} BACC: {bacc_score:.4f}\")\n",
    "    print(f\"[DEBUG] {phase} Prediction Distribution: {dict(Counter(all_preds))}\")\n",
    "    print(f\"[DEBUG] {phase} Label Distribution: {dict(Counter(all_labels))}\")\n",
    "    print(\"==================== Misclassification & Samples ====================\")\n",
    "    errors = [(i, p, pr, l) for i, (p, pr, l) in enumerate(zip(all_preds, all_probs, all_labels)) if p != l]\n",
    "    print(f\"{phase} Misclassified Samples: {len(errors)} / {len(all_labels)}\")\n",
    "    # for idx, pred, prob, label in errors[:10]:\n",
    "    #     print(f\"Idx {idx}: Pred = {pred}, Prob = {prob:.4f}, True = {label}\")\n",
    "    print(\"\\nSample Predictions vs Labels:\")\n",
    "    for i in range(min(sample_count, len(all_labels))):\n",
    "        print(f\"Sample {i+1}: Pred = {all_preds[i]}, Prob = {all_probs[i]:.4f}, True = {all_labels[i]}\")\n",
    "    print(\"=====================================================================\")\n",
    "    \n",
    "    return avg_loss, auc_score, acc_score, bacc_score, f1, all_labels, all_probs, best_threshold\n",
    "\n",
    "# ---------------------------------\n",
    "# Training\n",
    "# ---------------------------------\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, head_mode, schedular=None, num_epochs=5, model_save_path=\"best_model.pth\", device=device, save_plots=True):\n",
    "    best_val_auc = -np.inf\n",
    "    best_val_loss = np.inf\n",
    "    current_threshold = 0.5\n",
    "    best_threshold = 0.5\n",
    "\n",
    "    train_losses, val_losses = [], []\n",
    "    train_aucs, val_aucs = [], []\n",
    "    train_accs, val_accs = [], []\n",
    "    train_baccs, val_baccs = [], []\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        all_labels, all_probs, all_preds = [], [], []\n",
    "\n",
    "        #DEBUG\n",
    "        class_counts_train = {0:0, 1:0}\n",
    "        epoch_stats = defaultdict(list)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        for batch in tqdm(train_loader, desc=\"Train\"):\n",
    "            stft = batch['stft'].to(device)\n",
    "            cqt = batch['cqt'].to(device)\n",
    "            labels = batch['label'].to(device).long()\n",
    "\n",
    "            #DEBUG\n",
    "            for lbl in labels.cpu().numpy():\n",
    "                class_counts_train[int(lbl)] +=1\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(stft, cqt)\n",
    "\n",
    "            if head_mode in [\"classifier\", \"mlp\"]:\n",
    "                # Binary classification\n",
    "                if outputs.ndim == 2 and outputs.shape[1] == 2:\n",
    "                    probs = torch.softmax(outputs, dim=1)[:, 1]\n",
    "                    preds = torch.argmax(outputs.detach().cpu(), dim=1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                else:\n",
    "                    probs = torch.sigmoid(outputs.squeeze())\n",
    "                    preds = (probs > current_threshold ).long()\n",
    "                    loss = criterion(outputs.squeeze(), labels.float())\n",
    "            elif head_mode == \"prototype\":\n",
    "                embeddings, prototype = outputs\n",
    "                #DEBUG STARTS\n",
    "                #Cosine SIM LOGGING\n",
    "                embeddings = F.normalize(embeddings, dim=1)\n",
    "                prototype = F.normalize(prototype,dim=0)\n",
    "                if prototype.dim() == 1:\n",
    "                    prototype = prototype.unsqueeze(0)\n",
    "                prototype = prototype.expand_as(embeddings)\n",
    "                cos_sim = torch.sum(embeddings * prototype, dim=1)\n",
    "\n",
    "                normal_sim = cos_sim[labels == 0].mean().item() if (labels == 0).any() else None\n",
    "                anomaly_sim = cos_sim[labels ==1].mean().item() if (labels == 1).any() else None\n",
    "                if normal_sim is not None:\n",
    "                    epoch_stats['normal_sim'].append(normal_sim)\n",
    "                if anomaly_sim is not None:\n",
    "                    epoch_stats['anomaly_sim'].append(anomaly_sim)\n",
    "                \n",
    "                #DEBUG ENDS\n",
    "                anomaly_scores = 1 - cos_sim \n",
    "                probs = anomaly_scores\n",
    "                preds = (anomaly_scores > current_threshold).long()\n",
    "                loss = criterion(embeddings, prototype, labels.float())\n",
    "\n",
    "            elif head_mode == \"embedding\":\n",
    "                embeddings = outputs\n",
    "                normal_proto = model.head.normal_prototype\n",
    "                \n",
    "                #DEBUG STARTS\n",
    "                embeddings = F.normalize(embeddings, dim=1)\n",
    "                normal_proto = F.normalize(normal_proto, dim=0)\n",
    "                cos_sim = torch.sum(embeddings * normal_proto.unsqueeze(0).expand_as(embeddings), dim=1)\n",
    "\n",
    "                normal_sim = cos_sim[labels == 0].mean().item() if (labels == 0).any() else None\n",
    "                anomaly_sim = cos_sim[labels == 1].mean().item() if (labels == 1).any() else None\n",
    "                if normal_sim is not None:\n",
    "                    epoch_stats['normal_sim'].append(normal_sim)\n",
    "                if anomaly_sim is not None:\n",
    "                    epoch_stats['anomaly_sim'].append(anomaly_sim)\n",
    "                #DEBUG ENDS\n",
    "                \n",
    "                anomaly_scores = 1 - cos_sim \n",
    "                probs = anomaly_scores\n",
    "                preds = (anomaly_scores > current_threshold).long()\n",
    "                loss = criterion(embeddings,normal_proto, labels)\n",
    "            \n",
    "            elif head_mode == 'classifier-1':\n",
    "                outputs = model(stft, cqt)\n",
    "                probs = torch.sigmoid(outputs.squeeze())\n",
    "                preds = (probs > current_threshold).long()\n",
    "                loss = criterion(outputs.squeeze(), labels.float())\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported head_mode: {head_mode}\")\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * stft.size(0)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.detach().cpu().numpy())\n",
    "            all_preds.extend(preds.detach().cpu().numpy())\n",
    "        #DEBUG\n",
    "        print(f\"[DEBUG] Train label counts (epoch {epoch+1}): {class_counts_train}\") \n",
    "        if epoch_stats['normal_sim']:\n",
    "            avg_normal_sim = sum(epoch_stats['normal_sim']) / len(epoch_stats['normal_sim'])\n",
    "            avg_anomaly_sim = sum(epoch_stats['anomaly_sim']) / len(epoch_stats['anomaly_sim'])\n",
    "            print(f\"[DEBUG] Avg Normal CosSim: {avg_normal_sim:.4f}, Avg Anomaly CosSim: {avg_anomaly_sim:.4f}\")\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_auc = roc_auc_score(all_labels, all_probs) if len(np.unique(all_labels))> 1 else float('nan')\n",
    "        train_acc = accuracy_score(all_labels, all_preds)\n",
    "        train_bacc = balanced_accuracy_score(all_labels, all_preds)\n",
    "        train_aucs.append(train_auc)\n",
    "        train_accs.append(train_acc)\n",
    "        train_baccs.append(train_bacc)\n",
    "\n",
    "        print(f\"Train Loss: {epoch_loss:.4f} | Train AUC: {train_auc:.4f} | Train Acc: {train_acc:.4f}, | Train BAcc: {train_bacc:.4f}\")\n",
    "\n",
    "        # Validation\n",
    "        val_loss, val_auc, val_acc, val_bacc, _, _, _, current_optimal_threshold = evaluate_model(model, val_loader, criterion, phase=\"Validation\", device=device, head_mode=head_mode,sample_count=5)\n",
    "        val_losses.append(val_loss)\n",
    "        val_aucs.append(val_auc)\n",
    "        val_accs.append(val_acc)\n",
    "        val_baccs.append(val_bacc)\n",
    "\n",
    "        # scheduler step (per epoch)\n",
    "        if schedular is not None:\n",
    "            try:\n",
    "                schedular.step()\n",
    "            except Exception:\n",
    "                pass\n",
    "        print(f\"Epoch {epoch+1}: Learning Rate = {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            loss_path = model_save_path.replace(\".pth\", \"_best_loss.pth\")\n",
    "            torch.save(model.state_dict(), loss_path)\n",
    "            print(f\"Saved Best-Loss model to {loss_path} (val_loss improved to {best_val_loss:.4f})\")\n",
    "\n",
    "        # Save by best AUC\n",
    "        if not np.isnan(val_auc) and val_auc > best_val_auc:\n",
    "            best_val_auc = val_auc\n",
    "            best_threshold = current_optimal_threshold\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            print(f\"Saved Best-AUC model to {model_save_path} (val_auc improved to {best_val_auc:.4f})\")\n",
    "        else:\n",
    "            print(f\"Val AUC {val_auc:.4f} did not improved from best {best_val_auc:.4f}\")\n",
    "    \n",
    "    if save_plots:\n",
    "        epochs = range(1, num_epochs+1)\n",
    "        plt.figure(figsize=(18,4))\n",
    "        plt.subplot(1,4,1)\n",
    "        plt.plot(epochs, train_losses, label='Train Loss')\n",
    "        plt.plot(epochs, val_losses, label='Val Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.title(\"Train/Validation Loss\")\n",
    "\n",
    "        plt.subplot(1, 4, 2)\n",
    "        plt.plot(epochs, train_aucs, label='Train AUC')\n",
    "        plt.plot(epochs, val_aucs, label='Val AUC')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.title(\"Train/Validation AUC\")\n",
    "\n",
    "        plt.subplot(1, 4, 3)\n",
    "        plt.plot(epochs, train_accs, label='Train Acc')\n",
    "        plt.plot(epochs, val_accs, label='Val Acc')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.title(\"Train/Validation Accuracy\")\n",
    "\n",
    "        plt.subplot(1, 4, 4)\n",
    "        plt.plot(epochs, train_baccs, label='Train BAcc')\n",
    "        plt.plot(epochs, val_baccs, label='Val BAcc')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.title(\"Train/Validation Balanced Acc\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(save_path, \"training_summary.png\"))\n",
    "        # plt.show()\n",
    "\n",
    "    return best_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c669e74e",
   "metadata": {},
   "source": [
    "Main Pine Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667e62fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split sizes => Train: 2943, Val: 631, Test: 631\n",
      "Label Distribution (Train): Counter({0: 2624, 1: 319})\n",
      "Label Distribution (Validation): Counter({0: 562, 1: 69})\n",
      "Label Distribution (Test): Counter({0: 563, 1: 68})\n",
      "Used head:\n",
      " ComplexAnomalyMLP(\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.4, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.4, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Used transformations:\n",
      "  - ToTensor\n",
      "  - SpecTimePitchWarp\n",
      "    - time_scale: {1.1}\n",
      "    - freq_scale: {1.1}\n",
      "  - SpecAugment\n",
      "    - freq_mask_param: {4}\n",
      "    - time_mask_param: {4}\n",
      "    - n_freq_masks: {1}\n",
      "    - n_time_masks: {1}\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 91/91 [01:01<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Train label counts (epoch 1): {0: 1454, 1: 1458}\n",
      "Train Loss: 2.0027 | Train AUC: 0.5711 | Train Acc: 0.5021, | Train BAcc: 0.5014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 20/20 [00:03<00:00,  5.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Validation label counts: {0: 562, 1: 69}\n",
      "Optimal Threshold (F1-score): 0.94\n",
      "Best F1-score on Validation Set: 0.4048\n",
      "Validation Loss: 2.0935, Validation AUC: 0.7937, Validation ACC: 0.8415, Validation BACC: 0.6885\n",
      "[DEBUG] Validation Prediction Distribution: {np.int64(0): 532, np.int64(1): 99}\n",
      "[DEBUG] Validation Label Distribution: {np.int64(0): 562, np.int64(1): 69}\n",
      "==================== Misclassification & Samples ====================\n",
      "Validation Misclassified Samples: 100 / 631\n",
      "\n",
      "Sample Predictions vs Labels:\n",
      "Sample 1: Pred = 0, Prob = 0.8626, True = 0\n",
      "Sample 2: Pred = 0, Prob = 0.8270, True = 0\n",
      "Sample 3: Pred = 0, Prob = 0.9139, True = 1\n",
      "Sample 4: Pred = 0, Prob = 0.7734, True = 0\n",
      "Sample 5: Pred = 0, Prob = 0.9128, True = 0\n",
      "=====================================================================\n",
      "Epoch 1: Learning Rate = 0.000050\n",
      "Saved Best-Loss model to F:\\Capstone\\DFCA\\checkpoints\\DFCA\\[Anomaly-With-Transformations-dropout=0.4]_MLP(5e-5)\\ComplexMLP-75\\best_model_best_loss.pth (val_loss improved to 2.0935)\n",
      "Saved Best-AUC model to F:\\Capstone\\DFCA\\checkpoints\\DFCA\\[Anomaly-With-Transformations-dropout=0.4]_MLP(5e-5)\\ComplexMLP-75\\best_model.pth (val_auc improved to 0.7937)\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 91/91 [01:01<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Train label counts (epoch 2): {0: 1489, 1: 1423}\n",
      "Train Loss: 1.4983 | Train AUC: 0.6840 | Train Acc: 0.4887, | Train BAcc: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 20/20 [00:03<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Validation label counts: {0: 562, 1: 69}\n",
      "Optimal Threshold (F1-score): 0.93\n",
      "Best F1-score on Validation Set: 0.4734\n",
      "Validation Loss: 1.6826, Validation AUC: 0.8130, Validation ACC: 0.8590, Validation BACC: 0.7365\n",
      "[DEBUG] Validation Prediction Distribution: {np.int64(0): 531, np.int64(1): 100}\n",
      "[DEBUG] Validation Label Distribution: {np.int64(0): 562, np.int64(1): 69}\n",
      "==================== Misclassification & Samples ====================\n",
      "Validation Misclassified Samples: 89 / 631\n",
      "\n",
      "Sample Predictions vs Labels:\n",
      "Sample 1: Pred = 0, Prob = 0.6618, True = 0\n",
      "Sample 2: Pred = 0, Prob = 0.7583, True = 0\n",
      "Sample 3: Pred = 1, Prob = 0.9457, True = 1\n",
      "Sample 4: Pred = 0, Prob = 0.7048, True = 0\n",
      "Sample 5: Pred = 0, Prob = 0.6941, True = 0\n",
      "=====================================================================\n",
      "Epoch 2: Learning Rate = 0.000050\n",
      "Saved Best-Loss model to F:\\Capstone\\DFCA\\checkpoints\\DFCA\\[Anomaly-With-Transformations-dropout=0.4]_MLP(5e-5)\\ComplexMLP-75\\best_model_best_loss.pth (val_loss improved to 1.6826)\n",
      "Saved Best-AUC model to F:\\Capstone\\DFCA\\checkpoints\\DFCA\\[Anomaly-With-Transformations-dropout=0.4]_MLP(5e-5)\\ComplexMLP-75\\best_model.pth (val_auc improved to 0.8130)\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 91/91 [01:05<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Train label counts (epoch 3): {0: 1455, 1: 1457}\n",
      "Train Loss: 1.4187 | Train AUC: 0.7310 | Train Acc: 0.5003, | Train BAcc: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 20/20 [00:03<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Validation label counts: {0: 562, 1: 69}\n",
      "Optimal Threshold (F1-score): 0.89\n",
      "Best F1-score on Validation Set: 0.5605\n",
      "Validation Loss: 1.3686, Validation AUC: 0.8665, Validation ACC: 0.8906, Validation BACC: 0.7797\n",
      "[DEBUG] Validation Prediction Distribution: {np.int64(0): 543, np.int64(1): 88}\n",
      "[DEBUG] Validation Label Distribution: {np.int64(0): 562, np.int64(1): 69}\n",
      "==================== Misclassification & Samples ====================\n",
      "Validation Misclassified Samples: 69 / 631\n",
      "\n",
      "Sample Predictions vs Labels:\n",
      "Sample 1: Pred = 0, Prob = 0.7263, True = 0\n",
      "Sample 2: Pred = 0, Prob = 0.6119, True = 0\n",
      "Sample 3: Pred = 0, Prob = 0.8577, True = 1\n",
      "Sample 4: Pred = 0, Prob = 0.5802, True = 0\n",
      "Sample 5: Pred = 0, Prob = 0.7646, True = 0\n",
      "=====================================================================\n",
      "Epoch 3: Learning Rate = 0.000050\n",
      "Saved Best-Loss model to F:\\Capstone\\DFCA\\checkpoints\\DFCA\\[Anomaly-With-Transformations-dropout=0.4]_MLP(5e-5)\\ComplexMLP-75\\best_model_best_loss.pth (val_loss improved to 1.3686)\n",
      "Saved Best-AUC model to F:\\Capstone\\DFCA\\checkpoints\\DFCA\\[Anomaly-With-Transformations-dropout=0.4]_MLP(5e-5)\\ComplexMLP-75\\best_model.pth (val_auc improved to 0.8665)\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 91/91 [01:07<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Train label counts (epoch 4): {0: 1402, 1: 1510}\n",
      "Train Loss: 1.3511 | Train AUC: 0.7583 | Train Acc: 0.5185, | Train BAcc: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 20/20 [00:03<00:00,  5.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Validation label counts: {0: 562, 1: 69}\n",
      "Optimal Threshold (F1-score): 0.94\n",
      "Best F1-score on Validation Set: 0.5111\n",
      "Validation Loss: 1.5814, Validation AUC: 0.8602, Validation ACC: 0.8605, Validation BACC: 0.7755\n",
      "[DEBUG] Validation Prediction Distribution: {np.int64(0): 520, np.int64(1): 111}\n",
      "[DEBUG] Validation Label Distribution: {np.int64(0): 562, np.int64(1): 69}\n",
      "==================== Misclassification & Samples ====================\n",
      "Validation Misclassified Samples: 88 / 631\n",
      "\n",
      "Sample Predictions vs Labels:\n",
      "Sample 1: Pred = 0, Prob = 0.6866, True = 0\n",
      "Sample 2: Pred = 0, Prob = 0.6047, True = 0\n",
      "Sample 3: Pred = 1, Prob = 0.9495, True = 1\n",
      "Sample 4: Pred = 0, Prob = 0.5637, True = 0\n",
      "Sample 5: Pred = 0, Prob = 0.5239, True = 0\n",
      "=====================================================================\n",
      "Epoch 4: Learning Rate = 0.000049\n",
      "Val AUC 0.8602 did not improved from best 0.8665\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 91/91 [01:09<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Train label counts (epoch 5): {0: 1448, 1: 1464}\n",
      "Train Loss: 1.2329 | Train AUC: 0.8225 | Train Acc: 0.5416, | Train BAcc: 0.5391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 20/20 [00:03<00:00,  5.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Validation label counts: {0: 562, 1: 69}\n",
      "Optimal Threshold (F1-score): 0.91\n",
      "Best F1-score on Validation Set: 0.5862\n",
      "Validation Loss: 1.1390, Validation AUC: 0.9020, Validation ACC: 0.8859, Validation BACC: 0.8215\n",
      "[DEBUG] Validation Prediction Distribution: {np.int64(0): 526, np.int64(1): 105}\n",
      "[DEBUG] Validation Label Distribution: {np.int64(0): 562, np.int64(1): 69}\n",
      "==================== Misclassification & Samples ====================\n",
      "Validation Misclassified Samples: 72 / 631\n",
      "\n",
      "Sample Predictions vs Labels:\n",
      "Sample 1: Pred = 0, Prob = 0.5578, True = 0\n",
      "Sample 2: Pred = 0, Prob = 0.5681, True = 0\n",
      "Sample 3: Pred = 1, Prob = 0.9190, True = 1\n",
      "Sample 4: Pred = 0, Prob = 0.5101, True = 0\n",
      "Sample 5: Pred = 0, Prob = 0.4200, True = 0\n",
      "=====================================================================\n",
      "Epoch 5: Learning Rate = 0.000049\n",
      "Saved Best-Loss model to F:\\Capstone\\DFCA\\checkpoints\\DFCA\\[Anomaly-With-Transformations-dropout=0.4]_MLP(5e-5)\\ComplexMLP-75\\best_model_best_loss.pth (val_loss improved to 1.1390)\n",
      "Saved Best-AUC model to F:\\Capstone\\DFCA\\checkpoints\\DFCA\\[Anomaly-With-Transformations-dropout=0.4]_MLP(5e-5)\\ComplexMLP-75\\best_model.pth (val_auc improved to 0.9020)\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 91/91 [01:08<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Train label counts (epoch 6): {0: 1487, 1: 1425}\n",
      "Train Loss: 1.1885 | Train AUC: 0.8435 | Train Acc: 0.5666, | Train BAcc: 0.5754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 20/20 [00:04<00:00,  4.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Validation label counts: {0: 562, 1: 69}\n",
      "Optimal Threshold (F1-score): 0.98\n",
      "Best F1-score on Validation Set: 0.5772\n",
      "Validation Loss: 1.4300, Validation AUC: 0.9053, Validation ACC: 0.9002, Validation BACC: 0.7787\n",
      "[DEBUG] Validation Prediction Distribution: {np.int64(0): 551, np.int64(1): 80}\n",
      "[DEBUG] Validation Label Distribution: {np.int64(0): 562, np.int64(1): 69}\n",
      "==================== Misclassification & Samples ====================\n",
      "Validation Misclassified Samples: 63 / 631\n",
      "\n",
      "Sample Predictions vs Labels:\n",
      "Sample 1: Pred = 0, Prob = 0.6255, True = 0\n",
      "Sample 2: Pred = 0, Prob = 0.6157, True = 0\n",
      "Sample 3: Pred = 0, Prob = 0.9751, True = 1\n",
      "Sample 4: Pred = 0, Prob = 0.4282, True = 0\n",
      "Sample 5: Pred = 0, Prob = 0.1957, True = 0\n",
      "=====================================================================\n",
      "Epoch 6: Learning Rate = 0.000048\n",
      "Saved Best-AUC model to F:\\Capstone\\DFCA\\checkpoints\\DFCA\\[Anomaly-With-Transformations-dropout=0.4]_MLP(5e-5)\\ComplexMLP-75\\best_model.pth (val_auc improved to 0.9053)\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 91/91 [01:13<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Train label counts (epoch 7): {0: 1498, 1: 1414}\n",
      "Train Loss: 1.0917 | Train AUC: 0.8688 | Train Acc: 0.6339, | Train BAcc: 0.6439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 20/20 [00:04<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Validation label counts: {0: 562, 1: 69}\n",
      "Optimal Threshold (F1-score): 0.96\n",
      "Best F1-score on Validation Set: 0.6265\n",
      "Validation Loss: 1.1632, Validation AUC: 0.9180, Validation ACC: 0.9017, Validation BACC: 0.8368\n",
      "[DEBUG] Validation Prediction Distribution: {np.int64(0): 534, np.int64(1): 97}\n",
      "[DEBUG] Validation Label Distribution: {np.int64(0): 562, np.int64(1): 69}\n",
      "==================== Misclassification & Samples ====================\n",
      "Validation Misclassified Samples: 62 / 631\n",
      "\n",
      "Sample Predictions vs Labels:\n",
      "Sample 1: Pred = 0, Prob = 0.5939, True = 0\n",
      "Sample 2: Pred = 0, Prob = 0.3178, True = 0\n",
      "Sample 3: Pred = 1, Prob = 0.9743, True = 1\n",
      "Sample 4: Pred = 0, Prob = 0.1636, True = 0\n",
      "Sample 5: Pred = 0, Prob = 0.0719, True = 0\n",
      "=====================================================================\n",
      "Epoch 7: Learning Rate = 0.000048\n",
      "Saved Best-AUC model to F:\\Capstone\\DFCA\\checkpoints\\DFCA\\[Anomaly-With-Transformations-dropout=0.4]_MLP(5e-5)\\ComplexMLP-75\\best_model.pth (val_auc improved to 0.9180)\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 91/91 [01:13<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Train label counts (epoch 8): {0: 1457, 1: 1455}\n",
      "Train Loss: 1.0407 | Train AUC: 0.8791 | Train Acc: 0.6449, | Train BAcc: 0.6452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 20/20 [00:03<00:00,  5.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Validation label counts: {0: 562, 1: 69}\n",
      "Optimal Threshold (F1-score): 0.99\n",
      "Best F1-score on Validation Set: 0.6111\n",
      "Validation Loss: 1.3544, Validation AUC: 0.9173, Validation ACC: 0.9113, Validation BACC: 0.7913\n",
      "[DEBUG] Validation Prediction Distribution: {np.int64(0): 556, np.int64(1): 75}\n",
      "[DEBUG] Validation Label Distribution: {np.int64(0): 562, np.int64(1): 69}\n",
      "==================== Misclassification & Samples ====================\n",
      "Validation Misclassified Samples: 56 / 631\n",
      "\n",
      "Sample Predictions vs Labels:\n",
      "Sample 1: Pred = 0, Prob = 0.5903, True = 0\n",
      "Sample 2: Pred = 0, Prob = 0.3119, True = 0\n",
      "Sample 3: Pred = 1, Prob = 0.9933, True = 1\n",
      "Sample 4: Pred = 0, Prob = 0.1368, True = 0\n",
      "Sample 5: Pred = 0, Prob = 0.0342, True = 0\n",
      "=====================================================================\n",
      "Epoch 8: Learning Rate = 0.000047\n",
      "Val AUC 0.9173 did not improved from best 0.9180\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 91/91 [01:06<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Train label counts (epoch 9): {0: 1488, 1: 1424}\n",
      "Train Loss: 1.0399 | Train AUC: 0.8825 | Train Acc: 0.6755, | Train BAcc: 0.6821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 20/20 [00:03<00:00,  5.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Validation label counts: {0: 562, 1: 69}\n",
      "Optimal Threshold (F1-score): 0.95\n",
      "Best F1-score on Validation Set: 0.6471\n",
      "Validation Loss: 0.9904, Validation AUC: 0.9235, Validation ACC: 0.9239, Validation BACC: 0.7984\n",
      "[DEBUG] Validation Prediction Distribution: {np.int64(0): 564, np.int64(1): 67}\n",
      "[DEBUG] Validation Label Distribution: {np.int64(0): 562, np.int64(1): 69}\n",
      "==================== Misclassification & Samples ====================\n",
      "Validation Misclassified Samples: 48 / 631\n",
      "\n",
      "Sample Predictions vs Labels:\n",
      "Sample 1: Pred = 0, Prob = 0.4687, True = 0\n",
      "Sample 2: Pred = 0, Prob = 0.3188, True = 0\n",
      "Sample 3: Pred = 1, Prob = 0.9796, True = 1\n",
      "Sample 4: Pred = 0, Prob = 0.1996, True = 0\n",
      "Sample 5: Pred = 0, Prob = 0.1149, True = 0\n",
      "=====================================================================\n",
      "Epoch 9: Learning Rate = 0.000046\n",
      "Saved Best-Loss model to F:\\Capstone\\DFCA\\checkpoints\\DFCA\\[Anomaly-With-Transformations-dropout=0.4]_MLP(5e-5)\\ComplexMLP-75\\best_model_best_loss.pth (val_loss improved to 0.9904)\n",
      "Saved Best-AUC model to F:\\Capstone\\DFCA\\checkpoints\\DFCA\\[Anomaly-With-Transformations-dropout=0.4]_MLP(5e-5)\\ComplexMLP-75\\best_model.pth (val_auc improved to 0.9235)\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 91/91 [01:07<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Train label counts (epoch 10): {0: 1476, 1: 1436}\n",
      "Train Loss: 0.9488 | Train AUC: 0.9051 | Train Acc: 0.6992, | Train BAcc: 0.7030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 20/20 [00:03<00:00,  5.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Validation label counts: {0: 562, 1: 69}\n",
      "Optimal Threshold (F1-score): 0.97\n",
      "Best F1-score on Validation Set: 0.6623\n",
      "Validation Loss: 1.0643, Validation AUC: 0.9298, Validation ACC: 0.9176, Validation BACC: 0.8393\n",
      "[DEBUG] Validation Prediction Distribution: {np.int64(0): 546, np.int64(1): 85}\n",
      "[DEBUG] Validation Label Distribution: {np.int64(0): 562, np.int64(1): 69}\n",
      "==================== Misclassification & Samples ====================\n",
      "Validation Misclassified Samples: 52 / 631\n",
      "\n",
      "Sample Predictions vs Labels:\n",
      "Sample 1: Pred = 0, Prob = 0.3703, True = 0\n",
      "Sample 2: Pred = 0, Prob = 0.2368, True = 0\n",
      "Sample 3: Pred = 1, Prob = 0.9911, True = 1\n",
      "Sample 4: Pred = 0, Prob = 0.0968, True = 0\n",
      "Sample 5: Pred = 0, Prob = 0.0268, True = 0\n",
      "=====================================================================\n",
      "Epoch 10: Learning Rate = 0.000045\n",
      "Saved Best-AUC model to F:\\Capstone\\DFCA\\checkpoints\\DFCA\\[Anomaly-With-Transformations-dropout=0.4]_MLP(5e-5)\\ComplexMLP-75\\best_model.pth (val_auc improved to 0.9298)\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 91/91 [01:09<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Train label counts (epoch 11): {0: 1479, 1: 1433}\n",
      "Train Loss: 0.9245 | Train AUC: 0.9085 | Train Acc: 0.7105, | Train BAcc: 0.7147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 20/20 [00:03<00:00,  5.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Validation label counts: {0: 562, 1: 69}\n",
      "Optimal Threshold (F1-score): 0.96\n",
      "Best F1-score on Validation Set: 0.6569\n",
      "Validation Loss: 0.8762, Validation AUC: 0.9224, Validation ACC: 0.9255, Validation BACC: 0.8056\n",
      "[DEBUG] Validation Prediction Distribution: {np.int64(0): 563, np.int64(1): 68}\n",
      "[DEBUG] Validation Label Distribution: {np.int64(0): 562, np.int64(1): 69}\n",
      "==================== Misclassification & Samples ====================\n",
      "Validation Misclassified Samples: 47 / 631\n",
      "\n",
      "Sample Predictions vs Labels:\n",
      "Sample 1: Pred = 0, Prob = 0.3549, True = 0\n",
      "Sample 2: Pred = 0, Prob = 0.1079, True = 0\n",
      "Sample 3: Pred = 1, Prob = 0.9648, True = 1\n",
      "Sample 4: Pred = 0, Prob = 0.0423, True = 0\n",
      "Sample 5: Pred = 0, Prob = 0.0077, True = 0\n",
      "=====================================================================\n",
      "Epoch 11: Learning Rate = 0.000044\n",
      "Saved Best-Loss model to F:\\Capstone\\DFCA\\checkpoints\\DFCA\\[Anomaly-With-Transformations-dropout=0.4]_MLP(5e-5)\\ComplexMLP-75\\best_model_best_loss.pth (val_loss improved to 0.8762)\n",
      "Val AUC 0.9224 did not improved from best 0.9298\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 91/91 [01:09<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Train label counts (epoch 12): {0: 1503, 1: 1409}\n",
      "Train Loss: 0.9294 | Train AUC: 0.9066 | Train Acc: 0.7033, | Train BAcc: 0.7121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 20/20 [00:04<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Validation label counts: {0: 562, 1: 69}\n",
      "Optimal Threshold (F1-score): 0.97\n",
      "Best F1-score on Validation Set: 0.6463\n",
      "Validation Loss: 0.9243, Validation AUC: 0.9387, Validation ACC: 0.9081, Validation BACC: 0.8467\n",
      "[DEBUG] Validation Prediction Distribution: {np.int64(0): 536, np.int64(1): 95}\n",
      "[DEBUG] Validation Label Distribution: {np.int64(0): 562, np.int64(1): 69}\n",
      "==================== Misclassification & Samples ====================\n",
      "Validation Misclassified Samples: 58 / 631\n",
      "\n",
      "Sample Predictions vs Labels:\n",
      "Sample 1: Pred = 0, Prob = 0.1928, True = 0\n",
      "Sample 2: Pred = 0, Prob = 0.0639, True = 0\n",
      "Sample 3: Pred = 1, Prob = 0.9925, True = 1\n",
      "Sample 4: Pred = 0, Prob = 0.0025, True = 0\n",
      "Sample 5: Pred = 0, Prob = 0.0000, True = 0\n",
      "=====================================================================\n",
      "Epoch 12: Learning Rate = 0.000043\n",
      "Saved Best-AUC model to F:\\Capstone\\DFCA\\checkpoints\\DFCA\\[Anomaly-With-Transformations-dropout=0.4]_MLP(5e-5)\\ComplexMLP-75\\best_model.pth (val_auc improved to 0.9387)\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 91/91 [01:16<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Train label counts (epoch 13): {0: 1465, 1: 1447}\n",
      "Train Loss: 0.9135 | Train AUC: 0.9113 | Train Acc: 0.7284, | Train BAcc: 0.7299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 20/20 [00:04<00:00,  4.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Validation label counts: {0: 562, 1: 69}\n",
      "Optimal Threshold (F1-score): 0.99\n",
      "Best F1-score on Validation Set: 0.6667\n",
      "Validation Loss: 1.2899, Validation AUC: 0.9338, Validation ACC: 0.9239, Validation BACC: 0.8238\n",
      "[DEBUG] Validation Prediction Distribution: {np.int64(0): 556, np.int64(1): 75}\n",
      "[DEBUG] Validation Label Distribution: {np.int64(0): 562, np.int64(1): 69}\n",
      "==================== Misclassification & Samples ====================\n",
      "Validation Misclassified Samples: 48 / 631\n",
      "\n",
      "Sample Predictions vs Labels:\n",
      "Sample 1: Pred = 0, Prob = 0.7939, True = 0\n",
      "Sample 2: Pred = 0, Prob = 0.1846, True = 0\n",
      "Sample 3: Pred = 1, Prob = 0.9903, True = 1\n",
      "Sample 4: Pred = 0, Prob = 0.1437, True = 0\n",
      "Sample 5: Pred = 0, Prob = 0.0062, True = 0\n",
      "=====================================================================\n",
      "Epoch 13: Learning Rate = 0.000042\n",
      "Val AUC 0.9338 did not improved from best 0.9387\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 91/91 [01:10<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Train label counts (epoch 14): {0: 1446, 1: 1466}\n",
      "Train Loss: 0.9394 | Train AUC: 0.8949 | Train Acc: 0.7236, | Train BAcc: 0.7217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 20/20 [00:04<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Validation label counts: {0: 562, 1: 69}\n",
      "Optimal Threshold (F1-score): 0.96\n",
      "Best F1-score on Validation Set: 0.6341\n",
      "Validation Loss: 1.3388, Validation AUC: 0.9098, Validation ACC: 0.9049, Validation BACC: 0.8386\n",
      "[DEBUG] Validation Prediction Distribution: {np.int64(0): 536, np.int64(1): 95}\n",
      "[DEBUG] Validation Label Distribution: {np.int64(0): 562, np.int64(1): 69}\n",
      "==================== Misclassification & Samples ====================\n",
      "Validation Misclassified Samples: 60 / 631\n",
      "\n",
      "Sample Predictions vs Labels:\n",
      "Sample 1: Pred = 0, Prob = 0.8741, True = 0\n",
      "Sample 2: Pred = 0, Prob = 0.2265, True = 0\n",
      "Sample 3: Pred = 1, Prob = 0.9759, True = 1\n",
      "Sample 4: Pred = 0, Prob = 0.1501, True = 0\n",
      "Sample 5: Pred = 0, Prob = 0.0082, True = 0\n",
      "=====================================================================\n",
      "Epoch 14: Learning Rate = 0.000041\n",
      "Val AUC 0.9098 did not improved from best 0.9387\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 91/91 [01:10<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Train label counts (epoch 15): {0: 1427, 1: 1485}\n",
      "Train Loss: 0.9168 | Train AUC: 0.9075 | Train Acc: 0.7012, | Train BAcc: 0.6955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 20/20 [00:03<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Validation label counts: {0: 562, 1: 69}\n",
      "Optimal Threshold (F1-score): 0.97\n",
      "Best F1-score on Validation Set: 0.6447\n",
      "Validation Loss: 0.9321, Validation AUC: 0.9342, Validation ACC: 0.9144, Validation BACC: 0.8248\n",
      "[DEBUG] Validation Prediction Distribution: {np.int64(0): 548, np.int64(1): 83}\n",
      "[DEBUG] Validation Label Distribution: {np.int64(0): 562, np.int64(1): 69}\n",
      "==================== Misclassification & Samples ====================\n",
      "Validation Misclassified Samples: 54 / 631\n",
      "\n",
      "Sample Predictions vs Labels:\n",
      "Sample 1: Pred = 0, Prob = 0.3321, True = 0\n",
      "Sample 2: Pred = 0, Prob = 0.1741, True = 0\n",
      "Sample 3: Pred = 1, Prob = 0.9843, True = 1\n",
      "Sample 4: Pred = 0, Prob = 0.1051, True = 0\n",
      "Sample 5: Pred = 0, Prob = 0.0001, True = 0\n",
      "=====================================================================\n",
      "Epoch 15: Learning Rate = 0.000040\n",
      "Val AUC 0.9342 did not improved from best 0.9387\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 91/91 [01:11<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Train label counts (epoch 16): {0: 1495, 1: 1417}\n",
      "Train Loss: 0.7993 | Train AUC: 0.9331 | Train Acc: 0.7565, | Train BAcc: 0.7625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 20/20 [00:04<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Validation label counts: {0: 562, 1: 69}\n",
      "Optimal Threshold (F1-score): 0.98\n",
      "Best F1-score on Validation Set: 0.6584\n",
      "Validation Loss: 1.0118, Validation AUC: 0.9387, Validation ACC: 0.9128, Validation BACC: 0.8494\n",
      "[DEBUG] Validation Prediction Distribution: {np.int64(0): 539, np.int64(1): 92}\n",
      "[DEBUG] Validation Label Distribution: {np.int64(0): 562, np.int64(1): 69}\n",
      "==================== Misclassification & Samples ====================\n",
      "Validation Misclassified Samples: 55 / 631\n",
      "\n",
      "Sample Predictions vs Labels:\n",
      "Sample 1: Pred = 0, Prob = 0.3033, True = 0\n",
      "Sample 2: Pred = 0, Prob = 0.0611, True = 0\n",
      "Sample 3: Pred = 1, Prob = 0.9860, True = 1\n",
      "Sample 4: Pred = 0, Prob = 0.0176, True = 0\n",
      "Sample 5: Pred = 0, Prob = 0.0007, True = 0\n",
      "=====================================================================\n",
      "Epoch 16: Learning Rate = 0.000039\n",
      "Val AUC 0.9387 did not improved from best 0.9387\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 91/91 [01:10<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Train label counts (epoch 17): {0: 1448, 1: 1464}\n",
      "Train Loss: 0.8304 | Train AUC: 0.9257 | Train Acc: 0.7510, | Train BAcc: 0.7497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 20/20 [00:04<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Validation label counts: {0: 562, 1: 69}\n",
      "Optimal Threshold (F1-score): 0.92\n",
      "Best F1-score on Validation Set: 0.6424\n",
      "Validation Loss: 0.7873, Validation AUC: 0.9415, Validation ACC: 0.9065, Validation BACC: 0.8458\n",
      "[DEBUG] Validation Prediction Distribution: {np.int64(0): 535, np.int64(1): 96}\n",
      "[DEBUG] Validation Label Distribution: {np.int64(0): 562, np.int64(1): 69}\n",
      "==================== Misclassification & Samples ====================\n",
      "Validation Misclassified Samples: 59 / 631\n",
      "\n",
      "Sample Predictions vs Labels:\n",
      "Sample 1: Pred = 0, Prob = 0.3025, True = 0\n",
      "Sample 2: Pred = 0, Prob = 0.0274, True = 0\n",
      "Sample 3: Pred = 1, Prob = 0.9814, True = 1\n",
      "Sample 4: Pred = 0, Prob = 0.0028, True = 0\n",
      "Sample 5: Pred = 0, Prob = 0.0001, True = 0\n",
      "=====================================================================\n",
      "Epoch 17: Learning Rate = 0.000037\n",
      "Saved Best-Loss model to F:\\Capstone\\DFCA\\checkpoints\\DFCA\\[Anomaly-With-Transformations-dropout=0.4]_MLP(5e-5)\\ComplexMLP-75\\best_model_best_loss.pth (val_loss improved to 0.7873)\n",
      "Saved Best-AUC model to F:\\Capstone\\DFCA\\checkpoints\\DFCA\\[Anomaly-With-Transformations-dropout=0.4]_MLP(5e-5)\\ComplexMLP-75\\best_model.pth (val_auc improved to 0.9415)\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  96%|█████████▌| 87/91 [01:42<00:03,  1.00it/s]"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Main Pipeline \n",
    "# ================================\n",
    "def main():\n",
    "    \n",
    "    SEED = 42\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    train_transforms = ComposeT([\n",
    "        ToTensor(),\n",
    "        SpecTimePitchWarp(max_time_scale=1.1, max_freq_scale=1.1),\n",
    "        SpecAugment(freq_mask_param=4, time_mask_param=4, n_freq_masks=1, n_time_masks=1),\n",
    "    ])\n",
    "\n",
    "    no_transform = ComposeT([\n",
    "        ToTensor(),\n",
    "    ])\n",
    "\n",
    "    full_dataset = PairedSpectrogramDataset(FEATURES_DIR, transform=None)\n",
    "    all_labels = [int(x) for x in full_dataset.labels]\n",
    "\n",
    "    #Stratified Split [train/val/test]\n",
    "    idxs = list(range(len(full_dataset)))\n",
    "    train_idx, temp_idx = train_test_split(idxs, test_size=0.3, stratify=all_labels, random_state=42)\n",
    "    val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, stratify=[all_labels[i] for i in temp_idx], random_state=42)\n",
    "    \n",
    "    train_set = Subset(PairedSpectrogramDataset(FEATURES_DIR, transform=train_transforms), train_idx)\n",
    "    val_set = Subset(PairedSpectrogramDataset(FEATURES_DIR, transform=no_transform), val_idx)\n",
    "    test_set = Subset(PairedSpectrogramDataset(FEATURES_DIR, transform=no_transform), test_idx)\n",
    "    \n",
    "    # Added the sampler\n",
    "    train_labels = [all_labels[i] for i in train_idx]\n",
    "    counts = np.bincount(train_labels)\n",
    "    class_wgts = 1.0 / counts\n",
    "    sample_wgts = [float(class_wgts[label]) for label in train_labels ]\n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights=sample_wgts, \n",
    "        num_samples=len(sample_wgts), \n",
    "        replacement=True\n",
    "    )\n",
    "    # Added the sampler\n",
    "    train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, sampler=sampler, num_workers=0, drop_last=True)\n",
    "    val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "    test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "    # normal_transform = ComposeT([\n",
    "    #     ToTensor()\n",
    "    # ])\n",
    "\n",
    "    # abnormal_transform = ComposeT([\n",
    "    #     ToTensor(),\n",
    "    #     SpecTimePitchWarp(max_time_scale=1.1, max_freq_scale=1.1),\n",
    "    #     SpecAugment(freq_mask_param=4, time_mask_param=4, n_freq_masks=1, n_time_masks=1),\n",
    "    # ])\n",
    "\n",
    "    # class_to_transform = {\n",
    "    #     0: normal_transform,\n",
    "    #     1: abnormal_transform\n",
    "    # }\n",
    "\n",
    "    # full_dataset = PairedSpectrogramDatasetCS(FEATURES_DIR, class_to_transform=None)\n",
    "    # all_labels = [int(x) for x in full_dataset.labels] \n",
    "\n",
    "    # idxs = list(range(len(full_dataset)))\n",
    "    # train_idx, temp_idx = train_test_split(idxs, test_size=0.3, stratify=all_labels, random_state=42)\n",
    "    # val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, stratify=[all_labels[i] for i in temp_idx], random_state=42)\n",
    "\n",
    "    # train_set = Subset(PairedSpectrogramDatasetCS(FEATURES_DIR, class_to_transform=class_to_transform), train_idx)\n",
    "    # val_set   = Subset(PairedSpectrogramDatasetCS(FEATURES_DIR, class_to_transform={0: normal_transform, 1: normal_transform}), val_idx)\n",
    "    # test_set  = Subset(PairedSpectrogramDatasetCS(FEATURES_DIR, class_to_transform={0: normal_transform, 1: normal_transform}), test_idx)\n",
    "\n",
    "    # # --- Dataloaders ---\n",
    "    # train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, drop_last=True)\n",
    "    # val_loader   = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "    # test_loader  = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=0) \n",
    "    \n",
    "    print(f\"Split sizes => Train: {len(train_set)}, Val: {len(val_set)}, Test: {len(test_set)}\")\n",
    "    print(\"Label Distribution (Train):\",Counter([int(full_dataset[i]['label']) for i in train_idx]))\n",
    "    print(\"Label Distribution (Validation):\",Counter([int(full_dataset[i]['label']) for i in val_idx]))\n",
    "    print(\"Label Distribution (Test):\",Counter([int(full_dataset[i]['label']) for i in test_idx]))\n",
    "    \n",
    "    head_mode = HEAD_MODE.lower()\n",
    "    \n",
    "    if head_mode == 'prototype':\n",
    "        head = AnomalyScorer(in_dim=256, dropout=0.4, mode='prototype')\n",
    "        criterion = ContrastiveLoss(margin=CONTRASTIVE_MARGIN)\n",
    "        print(f\"Used head:\\n {head}\")\n",
    "        print(\"Used transformations:\")\n",
    "        for transform in train_transforms.transforms:\n",
    "            # Print the name of the transformation class\n",
    "            print(f\"  - {transform.__class__.__name__}\")\n",
    "    \n",
    "            # Check for specific transformations and print their parameters\n",
    "            if isinstance(transform, SpecTimePitchWarp):\n",
    "\n",
    "                print(f\"    - time_scale: {getattr(transform, 'max_time_scale', {transform.max_time})}\")\n",
    "                print(f\"    - freq_scale: {getattr(transform, 'max_freq_scale', {transform.max_freq})}\")\n",
    "            if isinstance(transform, SpecAugment):\n",
    "                print(f\"    - freq_mask_param: {getattr(transform,'freq_mask_param',{transform.fm})}\")\n",
    "                print(f\"    - time_mask_param: {getattr(transform,'time_mask_param',{transform.tm})}\")\n",
    "                print(f\"    - n_freq_masks: {getattr(transform,'n_freq_masks', {transform.nf})}\")\n",
    "                print(f\"    - n_time_masks: {getattr(transform,'n_time_masks', {transform.nt})}\")\n",
    "    elif HEAD_MODE == 'mlp':\n",
    "        #head = SimpleAnomalyMLP(in_dim=256, dropout=0.4,hidden=128, out_dim=1)\n",
    "        head = ComplexAnomalyMLP(in_dim=256, dropout=0.4, out_dim=1)\n",
    "        pos_count = sum(all_labels)\n",
    "        neg_count = len(all_labels) - pos_count\n",
    "        pos_weight = torch.tensor([neg_count / (pos_count + 1e-8)], dtype=torch.float32).to(device)\n",
    "        criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "        print(f\"Used head:\\n {head}\")\n",
    "        print(\"Used transformations:\")\n",
    "        for transform in train_transforms.transforms:\n",
    "            # Print the name of the transformation class\n",
    "            print(f\"  - {transform.__class__.__name__}\")\n",
    "    \n",
    "            # Check for specific transformations and print their parameters\n",
    "            if isinstance(transform, SpecTimePitchWarp):\n",
    "\n",
    "                print(f\"    - time_scale: {getattr(transform, 'max_time_scale',{transform.max_time} )}\")\n",
    "                print(f\"    - freq_scale: {getattr(transform, 'max_freq_scale', {transform.max_freq})}\")\n",
    "            if isinstance(transform, SpecAugment):\n",
    "                print(f\"    - freq_mask_param: {getattr(transform,'freq_mask_param',{transform.fm})}\")\n",
    "                print(f\"    - time_mask_param: {getattr(transform,'time_mask_param',{transform.tm})}\")\n",
    "                print(f\"    - n_freq_masks: {getattr(transform,'n_freq_masks',{transform.nf})}\")\n",
    "                print(f\"    - n_time_masks: {getattr(transform,'n_time_masks',{transform.nt})}\")\n",
    "    elif HEAD_MODE == 'embedding':\n",
    "        head = EmbeddingMLP(in_dim=256, hidden=128, dropout=0.4, emb_dim=64)\n",
    "        criterion = ContrastiveLoss(margin=CONTRASTIVE_MARGIN)\n",
    "        print(f\"Used head:\\n {head}\")\n",
    "        print(\"Used transformations:\")\n",
    "        for transform in train_transforms.transforms:\n",
    "            # Print the name of the transformation class\n",
    "            print(f\"  - {transform.__class__.__name__}\")\n",
    "    \n",
    "            # Check for specific transformations and print their parameters\n",
    "            if isinstance(transform, SpecTimePitchWarp):\n",
    "\n",
    "                print(f\"    - time_scale: {getattr(transform, 'max_time_scale', {transform.max_time})}\")\n",
    "                print(f\"    - freq_scale: {getattr(transform, 'max_freq_scale', {transform.max_freq})}\")\n",
    "            if isinstance(transform, SpecAugment):\n",
    "                print(f\"    - freq_mask_param: {getattr(transform,'freq_mask_param',{transform.fm})}\")\n",
    "                print(f\"    - time_mask_param: {getattr(transform,'time_mask_param',{transform.tm})}\")\n",
    "                print(f\"    - n_freq_masks: {getattr(transform,'n_freq_masks',{transform.nf})}\")\n",
    "                print(f\"    - n_time_masks: {getattr(transform,'n_time_masks',{transform.nt})}\")\n",
    "    elif HEAD_MODE == 'classifier':\n",
    "        head = SimpleAnomalyMLP(in_dim=256, dropout=0.4, hidden=128, out_dim=2)\n",
    "        class_counts = [2624, 319]\n",
    "        \n",
    "        alpha = 0.7\n",
    "        total = sum(class_counts)\n",
    "        class_weights = [(total / c) ** alpha for c in class_counts]  \n",
    "        class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "        print(f\"Using head: {head}\")\n",
    "        print(\"Used transformations:\")\n",
    "        for transform in train_transforms.transforms:\n",
    "            # Print the name of the transformation class\n",
    "            print(f\"  - {transform.__class__.__name__}\")\n",
    "    \n",
    "            # Check for specific transformations and print their parameters\n",
    "            if isinstance(transform, SpecTimePitchWarp):\n",
    "\n",
    "                print(f\"    - time_scale: {getattr(transform, 'max_time_scale', {transform.max_time})}\")\n",
    "                print(f\"    - freq_scale: {getattr(transform, 'max_freq_scale', {transform.max_freq})}\")\n",
    "            if isinstance(transform, SpecAugment):\n",
    "                print(f\"    - freq_mask_param: {getattr(transform,'freq_mask_param',{transform.fm})}\")\n",
    "                print(f\"    - time_mask_param: {getattr(transform,'time_mask_param', {transform.tm})}\")\n",
    "                print(f\"    - n_freq_masks: {getattr(transform,'n_freq_masks',{transform.nf})}\")\n",
    "                print(f\"    - n_time_masks: {getattr(transform,'n_time_masks',{transform.nt})}\")\n",
    "    elif HEAD_MODE == 'classifier-1':\n",
    "        head = AnomalyScorer(in_dim=256, dropout=0.4, mode='classifier-1')\n",
    "        pos_count = sum(all_labels)\n",
    "        neg_count = len(all_labels) - pos_count\n",
    "        pos_weight = torch.tensor([neg_count / (pos_count + 1e-8)], dtype=torch.float32).to(device)\n",
    "        criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "        print(f\"Using head: \\n{head}\")\n",
    "        print(\"Used transformations:\")\n",
    "        for transform in train_transforms.transforms:\n",
    "            print(f\"- {transform.__class__.__name__}\")\n",
    "            if isinstance(transform, SpecTimePitchWarp):\n",
    "\n",
    "                print(f\"    - time_scale: {getattr(transform, 'max_time_scale', {transform.max_time})}\")\n",
    "                print(f\"    - freq_scale: {getattr(transform, 'max_freq_scale', {transform.max_freq})}\")\n",
    "            if isinstance(transform, SpecAugment):\n",
    "                print(f\"    - freq_mask_param: {getattr(transform,'freq_mask_param',{transform.fm})}\")\n",
    "                print(f\"    - time_mask_param: {getattr(transform,'time_mask_param', {transform.tm})}\")\n",
    "                print(f\"    - n_freq_masks: {getattr(transform,'n_freq_masks',{transform.nf})}\")\n",
    "                print(f\"    - n_time_masks: {getattr(transform,'n_time_masks',{transform.nt})}\")\n",
    "    else:\n",
    "        raise ValueError(\"Invalid Head_Mode\")\n",
    "    \n",
    "    model = FusedModel(\n",
    "        stft_dim=512, cqt_dim=320, fusion_dim=256, head=head, head_mode=head_mode,\n",
    "    ).to(device)\n",
    "    \n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS, eta_min=1e-6)\n",
    "    \n",
    "    model_path = os.path.join(CHECKPOINT_DIR, 'DFCA', '[Anomaly-With-Transformations-dropout=0.4]_MLP(5e-5)','ComplexMLP-75', \"best_model.pth\")\n",
    "    os.makedirs(os.path.dirname(model_path), exist_ok=True)  \n",
    "    best_threshold = train_model(model, train_loader, val_loader, criterion, optimizer, head_mode, scheduler, num_epochs=NUM_EPOCHS, model_save_path=model_path, device=device, save_plots=True)\n",
    "    \n",
    "    print(\"\\n--- Final Test Evaluation ---\")\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    safe_threshold = float(best_threshold) if best_threshold is not None else 0.5\n",
    "\n",
    "    test_loss, test_auc, test_acc, test_bacc, test_f1, all_labels_test, all_probs_test, _ = evaluate_model(model, test_loader, criterion, \"Test\", device, head_mode=head_mode, sample_count=5, threshold=safe_threshold)\n",
    "    print(f\"\\nFinal Test Metrics (with best validation threshold {best_threshold:.2f}):\")\n",
    "    print(f\"Loss: {test_loss:.4f} | AUC: {test_auc:.4f} | Accuracy: {test_acc:.4f} | Balanced Accuracy: {test_bacc:.4f} | F1-Score: {test_f1:.4f}\")\n",
    "    if len(np.unique(all_labels_test)) > 1:\n",
    "        final_pauc = calculate_pAUC(all_labels_test, all_probs_test, max_fpr=0.2)\n",
    "        print(f\"Final Test pAUC (FPR <= 0.2): {final_pauc:.4f}\")\n",
    "    else:\n",
    "        print(\"Test set contains only one class; cannot compute AUC/pAUC\")\n",
    "\n",
    "\n",
    "    # Plot ROC\n",
    "    fpr, tpr, _ = roc_curve(all_labels_test, all_probs_test)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.plot(fpr, tpr, lw=2, label=f\"{test_auc:.4f}\")\n",
    "    plt.plot([0,1],[0,1], linestyle='--', lw=1)\n",
    "    plt.xlabel(\"FPR\")\n",
    "    plt.ylabel(\"TPR\")\n",
    "    plt.title(\"Test ROC With Optimal Threshold\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(save_path,\"roc_test_optimal.png\"))\n",
    "    # plt.show()\n",
    "\n",
    "    labels = ['Normal', 'Anomaly']\n",
    "    all_preds_test = (np.array(all_probs_test) > safe_threshold).astype(int)\n",
    "    plot_confusion_matrix(all_labels_test, all_preds_test,labels,save_path,title='Test Set Confusion Matrix')\n",
    "\n",
    "    try:\n",
    "        cams = build_gradcam_for_model(model, device)\n",
    "        run_and_save_gradcams(model, cams, test_set,device, out_dir=os.path.join(CHECKPOINT_DIR,'DFCA','[Anomaly-With-Transformations-dropout=0.4]_MLP(5e-5)','ComplexMLP-75','gradcam'),n_samples=8)\n",
    "    except Exception as error:\n",
    "        print(f\"GradCAM step failed: {error}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
