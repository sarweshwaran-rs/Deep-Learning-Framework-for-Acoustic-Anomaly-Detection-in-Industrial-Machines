{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-01T17:46:06.842228Z",
     "iopub.status.busy": "2025-09-01T17:46:06.842028Z",
     "iopub.status.idle": "2025-09-01T17:46:12.313890Z",
     "shell.execute_reply": "2025-09-01T17:46:12.313245Z",
     "shell.execute_reply.started": "2025-09-01T17:46:06.842211Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio.transforms as T\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from collections import Counter, defaultdict\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, balanced_accuracy_score, roc_curve, auc, f1_score, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from torchvision.models import resnet18\n",
    "from timm import create_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T17:46:12.315011Z",
     "iopub.status.busy": "2025-09-01T17:46:12.314726Z",
     "iopub.status.idle": "2025-09-01T17:46:12.330864Z",
     "shell.execute_reply": "2025-09-01T17:46:12.330140Z",
     "shell.execute_reply.started": "2025-09-01T17:46:12.314988Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class PairedSpectrogramDataset(Dataset):\n",
    "    def __init__(self, base_dir, transform=None): #Added the transfomration option\n",
    "        self.transform = transform\n",
    "        self.stft_paths, self.cqt_paths = [], []\n",
    "        self.labels = []\n",
    "        self.categories, self.machine_ids = [], []\n",
    "\n",
    "        for machine in os.listdir(base_dir):\n",
    "            machine_path = os.path.join(base_dir, machine)\n",
    "            if not os.path.isdir(machine_path):\n",
    "                continue\n",
    "            machine_id = int(machine.split('_')[-1]) #id_00 -> 0\n",
    "            for category in ['normal', 'abnormal']:\n",
    "                stft_dir = os.path.join(machine_path, category, 'stft')\n",
    "                cqt_dir = os.path.join(machine_path, category, 'cqt')\n",
    "\n",
    "                if not (os.path.isdir(stft_dir) and os.path.isdir(cqt_dir)):\n",
    "                    continue\n",
    "\n",
    "                for filename in os.listdir(stft_dir):\n",
    "                    if filename.endswith('.npy'):\n",
    "                        stft_path = os.path.join(stft_dir, filename)\n",
    "                        cqt_path = os.path.join(cqt_dir, filename)\n",
    "\n",
    "                        self.stft_paths.append(stft_path)\n",
    "                        self.cqt_paths.append(cqt_path)\n",
    "                        self.labels.append(0 if category == 'normal' else 1)\n",
    "                        self.machine_ids.append(machine_id)\n",
    "                        self.categories.append(category)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.stft_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        stft = torch.tensor(np.load(self.stft_paths[idx]), dtype=torch.float32).unsqueeze(0)\n",
    "        cqt = torch.tensor(np.load(self.cqt_paths[idx]), dtype=torch.float32).unsqueeze(0)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            stft = self.transform(stft)\n",
    "            cqt = self.transform(cqt)\n",
    "                         \n",
    "        return {\n",
    "            'stft': stft, \n",
    "            'cqt': cqt, \n",
    "            'label' :self.labels[idx],\n",
    "            'machine_id': self.machine_ids[idx],\n",
    "            'category': self.categories[idx],\n",
    "            'stft_path': self.stft_paths[idx],\n",
    "            'cqt_path' : self.cqt_paths[idx]\n",
    "        }\n",
    "\n",
    "\n",
    "class ComposeT:\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms= transforms\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for t in self.transforms:\n",
    "            x = t(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class ToTensor:\n",
    "    def __call__(self, x):\n",
    "        if isinstance(x, np.ndarray):\n",
    "            x = torch.from_numpy(x).float()\n",
    "        elif not torch.is_tensor(x):\n",
    "            x = torch.tensor(x).float()\n",
    "        return x\n",
    "\n",
    "\n",
    "class SpecAugment:\n",
    "    \"\"\"\n",
    "    Frequency and Time Masking on Spectrograms.  Accepts (freq, time) or (1, freq, time).\n",
    "    \"\"\"\n",
    "    def __init__(self, freq_mask_param=15, time_mask_param=35, n_freq_masks=1, n_time_masks=1):\n",
    "        self.fm = freq_mask_param\n",
    "        self.tm = time_mask_param\n",
    "        self.FM = torchaudio.transforms.FrequencyMasking(self.fm)\n",
    "        self.TM = torchaudio.transforms.TimeMasking(self.tm)\n",
    "        self.nf = n_freq_masks\n",
    "        self.nt = n_time_masks\n",
    "\n",
    "    def __call__(self, spec):\n",
    "        if isinstance(spec, np.ndarray):\n",
    "            spec = torch.from_numpy(spec).float()\n",
    "        if spec.ndim == 2: #[F,T]\n",
    "            spec = spec.unsqueeze(0) # (1,F,T)\n",
    "        elif spec.ndim == 4: #(B,C,F,T)\n",
    "            raise ValueError(\"SpecAugment expects single spectrogram, got batched input\")\n",
    "        \n",
    "        for _ in range(self.nf): \n",
    "            spec = self.FM(spec)\n",
    "        for _ in range(self.nt):\n",
    "            spec = self.TM(spec)\n",
    "        \n",
    "        return spec\n",
    "\n",
    "class SpecTimePitchWarp:\n",
    "    \"\"\"\n",
    "    Approximate time-stretch / pitch-shift by scaling time/freq axes of the spectrogram.\n",
    "    This is an approximation for when you have only spectrograms.\n",
    "    \"\"\"\n",
    "    def __init__(self, max_time_scale=1.2, max_freq_scale=1.1):\n",
    "        self.max_time = max_time_scale\n",
    "        self.max_freq = max_freq_scale\n",
    "\n",
    "    def _resize_and_crop(self, spec, target_f, target_t):\n",
    "        _, F, T= spec.shape\n",
    "\n",
    "        spec = spec.unsqueeze(0) #(1,C,F,T)\n",
    "        spec = torch.nn.functional.interpolate(spec, size=(target_f, target_t), mode='bilinear', align_corners=False)\n",
    "        spec = spec.squeeze(0)\n",
    "\n",
    "        start_f = max(0, (spec.shape[1] - F) // 2)\n",
    "        start_t = max(0, (spec.shape[2] - T) // 2)\n",
    "        spec = spec[:, start_f:start_f+F, start_t:start_t+T]\n",
    "        \n",
    "        if spec.shape[1] < F or spec.shape[2] < T:\n",
    "            pad_f = F - spec.shape[1]\n",
    "            pad_t = T - spec.shape[2]\n",
    "            spec = torch.nn.functional.pad(spec, (0, pad_t, 0, pad_f))\n",
    "        \n",
    "        return spec\n",
    "    \n",
    "    def __call__(self, spec):\n",
    "        if isinstance(spec, np.ndarray):\n",
    "            spec = torch.from_numpy(spec).float()\n",
    "\n",
    "        # Handle shape\n",
    "        if spec.ndim == 2:        # (F, T)\n",
    "            spec = spec.unsqueeze(0)  # (1, F, T)\n",
    "        elif spec.ndim == 4:      # (B, C, F, T) -> not supported here\n",
    "            raise ValueError(\"SpecTimePitchWarp expects single spectrogram, got batched input\")\n",
    "\n",
    "        _, F, T = spec.shape\n",
    "        t_scale = random.uniform(1.0 / self.max_time, self.max_time)\n",
    "        f_scale = random.uniform(1.0 / self.max_freq, self.max_freq)\n",
    "        newT = max(2, int(T * t_scale))\n",
    "        newF = max(2, int(F * f_scale))\n",
    "\n",
    "        spec = self._resize_and_crop(spec, newF, newT)\n",
    "        return spec  # (C, F, T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extractor, CAFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T17:46:12.331721Z",
     "iopub.status.busy": "2025-09-01T17:46:12.331457Z",
     "iopub.status.idle": "2025-09-01T17:46:12.355157Z",
     "shell.execute_reply": "2025-09-01T17:46:12.354451Z",
     "shell.execute_reply.started": "2025-09-01T17:46:12.331694Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class STFTFrequencyAdaptiveFeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        resnet = resnet18(weights=None)\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            resnet.bn1,\n",
    "            resnet.relu,\n",
    "            resnet.maxpool\n",
    "        )\n",
    "        self.layer1 = resnet.layer1\n",
    "        self.layer2 = resnet.layer2\n",
    "\n",
    "        self.layer3 = self._make_adaptive_layer(resnet.layer3, kernel_size = (1,7))\n",
    "        self.layer4 = self._make_adaptive_layer(resnet.layer4, kernel_size = (1,15))\n",
    "\n",
    "    def _make_adaptive_layer(self, layer, kernel_size):\n",
    "        for block in layer:\n",
    "            block.conv1 = nn.Conv2d(\n",
    "                in_channels=block.conv1.in_channels,\n",
    "                out_channels=block.conv1.out_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=block.conv1.stride,\n",
    "                padding=(kernel_size[0] // 2, kernel_size[1] // 2),\n",
    "                bias=False \n",
    "            )\n",
    "\n",
    "            block.conv2 = nn.Conv2d(\n",
    "                in_channels=block.conv2.in_channels,\n",
    "                out_channels=block.conv2.out_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=block.conv2.stride,\n",
    "                padding=(kernel_size[0] // 2, kernel_size[1] // 2),\n",
    "                bias=False\n",
    "            )\n",
    "            \n",
    "        return layer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        return x\n",
    "\n",
    "# CQT Feature Extractor using the mobilevit_xxs model\n",
    "class CQTFeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = create_model('mobilevit_xxs', pretrained=False,num_classes=0, global_pool='')\n",
    "\n",
    "        self.model.stem.conv = nn.Conv2d( # type: ignore\n",
    "            1, 16, kernel_size=3, stride=2, padding=1, bias=False\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.model(x)\n",
    "\n",
    "#Projection + Polling Block to Match the Channels, Height, and Width of the Extractor Features to Match with the Shape(4,16) with 256 Channel Size\n",
    "class FeatureProjector(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels=256, target_hw=(4,16)):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1)\n",
    "        self.pool = nn.AdaptiveAvgPool2d(target_hw)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.proj(x)\n",
    "        x = self.pool(x)\n",
    "        return x\n",
    "\n",
    "class CAFM(nn.Module):\n",
    "    def __init__(self, dim=256):\n",
    "        super().__init__()\n",
    "        self.wq1= nn.Linear(dim, dim)\n",
    "        self.wq2 = nn.Linear(dim, dim)\n",
    "        self.wq3 = nn.Linear(dim, dim)\n",
    "\n",
    "        self.wq4 = nn.Linear(dim, dim)\n",
    "        self.wq5 = nn.Linear(dim, dim)\n",
    "        self.wq6 = nn.Linear(dim, dim)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(dim * 2, dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dim, dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, stft_feat, cqt_feat):\n",
    "        B, C, H, W = stft_feat.shape\n",
    "        assert stft_feat.shape == cqt_feat.shape, \"Shape mismatch between STFT and CQT features\"\n",
    "\n",
    "        stft_seq = stft_feat.flatten(2).transpose(1, 2) # [B, N, C]\n",
    "        cqt_seq = cqt_feat.flatten(2).transpose(1, 2) # [B, N, C]\n",
    "\n",
    "        # STFT attends to CQT\n",
    "        Q1 = self.wq1(stft_seq)\n",
    "        K1 = self.wq2(cqt_seq)\n",
    "        V1 = self.wq3(cqt_seq)\n",
    "        dk = Q1.size(-1)\n",
    "        attention_1 = self.softmax(torch.bmm(Q1, K1.transpose(1, 2)) / (dk ** 0.5))\n",
    "        out_1 = torch.bmm(attention_1, V1)\n",
    "\n",
    "        # CQT attends to STFT\n",
    "        Q2 = self.wq4(cqt_seq)\n",
    "        K2 = self.wq5(stft_seq)\n",
    "        V2 = self.wq6(stft_seq)\n",
    "        attention_2 = self.softmax(torch.bmm(Q2, K2.transpose(1, 2)) / (dk ** 0.5))\n",
    "        out_2 = torch.bmm(attention_2, V2)\n",
    "\n",
    "        # Mean pool and Fuse\n",
    "        fused = torch.cat([out_1.mean(1), out_2.mean(1)], dim=1)\n",
    "        # print(f\"Fused shape before MLP[Multi Layer Perceptron]: {fused.shape}\")\n",
    "        output = self.out(fused)\n",
    "        # print(f\"Output shape after MLP [Multi Layer Perceptron]: {output.shape}\")\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fused Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T17:46:12.357106Z",
     "iopub.status.busy": "2025-09-01T17:46:12.356898Z",
     "iopub.status.idle": "2025-09-01T17:46:12.375827Z",
     "shell.execute_reply": "2025-09-01T17:46:12.375213Z",
     "shell.execute_reply.started": "2025-09-01T17:46:12.357090Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class FusedModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Dual-branch model with spectral positional encoding and optional temporal smoothing decoder.\n",
    "\n",
    "    Args:\n",
    "        stft_dim (int): Output channels for STFT branch projector.\n",
    "        cqt_dim (int): Output channels for CQT branch projector.\n",
    "        fusion_dim (int): Output channels for fusion block.\n",
    "        head (nn.Module, optional): Classification or embedding head module.\n",
    "        head_mode (str): Head output mode. Default 'classifier-1'.\n",
    "    \"\"\"\n",
    "    def __init__(self,stft_dim=512,cqt_dim=320,fusion_dim=256,head=None):\n",
    "        super().__init__()\n",
    "        self.head = head\n",
    "\n",
    "        # Feature extractors\n",
    "        self.stft_net = STFTFrequencyAdaptiveFeatureExtractor()\n",
    "        self.cqt_net = CQTFeatureExtractor()\n",
    "        self.stft_proj = FeatureProjector(stft_dim)\n",
    "        self.cqt_proj = FeatureProjector(cqt_dim)\n",
    "        self.fuser = CAFM(fusion_dim)\n",
    "    \n",
    "    def forward(self, stft, cqt):\n",
    "        if stft.dim() != 4 or cqt.dim() != 4:\n",
    "            raise ValueError(\"use_decoder=False expects [B, C, H, W] inputs\")\n",
    "\n",
    "        stft_feat = self.stft_proj(self.stft_net(stft))\n",
    "        cqt_feat  = self.cqt_proj(self.cqt_net(cqt))\n",
    "        if stft_feat.dim() != 4 or cqt_feat.dim() != 4:\n",
    "            raise RuntimeError(\n",
    "                f\"Expected 4D tensors before CAFM, got stft:{stft_feat.shape}, cqt:{cqt_feat.shape}. \"\n",
    "                \"Check FeatureProjector to ensure it does not flatten.\"\n",
    "            )\n",
    "\n",
    "        fused = self.fuser(stft_feat, cqt_feat) # [B, fusion_dim]\n",
    "        if self.head is None:\n",
    "            return fused\n",
    "        return self.head(fused)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T17:46:12.377170Z",
     "iopub.status.busy": "2025-09-01T17:46:12.376712Z",
     "iopub.status.idle": "2025-09-01T17:46:12.391438Z",
     "shell.execute_reply": "2025-09-01T17:46:12.390608Z",
     "shell.execute_reply.started": "2025-09-01T17:46:12.377151Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class AnomalyScorer(nn.Module):\n",
    "    def __init__(self, in_dim=256, dropout = 0.4, mode = 'classifier-1'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mode = mode\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        if mode == 'classifier-1':\n",
    "            self.head = nn.Sequential(\n",
    "                nn.Linear(in_dim, 128),\n",
    "                nn.ReLU(),\n",
    "                self.dropout,\n",
    "                nn.Linear(128,1), # Binary Classification\n",
    "            )\n",
    "        elif mode == 'prototype':\n",
    "            self.prototype = nn.Parameter(torch.randn(in_dim)) # Learnable normal prototype\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.mode == 'classifier-1':\n",
    "            return self.head(x) # logits for BCEWithLogitsLoss\n",
    "        \n",
    "        elif self.mode == 'prototype':\n",
    "            if x.dim() == 3:\n",
    "                x = x.mean(dim=1)\n",
    "            \n",
    "            x = self.dropout(x)\n",
    "            dist = torch.norm(x - self.prototype, dim=1, keepdim=True)\n",
    "            return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T17:46:12.392349Z",
     "iopub.status.busy": "2025-09-01T17:46:12.392136Z",
     "iopub.status.idle": "2025-09-01T17:46:12.411928Z",
     "shell.execute_reply": "2025-09-01T17:46:12.411276Z",
     "shell.execute_reply.started": "2025-09-01T17:46:12.392334Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calculate_pAUC(labels, preds, max_fpr = 0.1):\n",
    "    \"\"\"\n",
    "    Calculates Partial AUC (pAUC) for a given FPR range.\n",
    "    Args:\n",
    "        labels (array): True binary labels.\n",
    "        preds (array): Predicted probabilities for the positive class.\n",
    "        max_fpr (float): Maximum False Positive Rate for pAUC calculation.\n",
    "    Returns:\n",
    "        float: pAUC score.\n",
    "    \"\"\"\n",
    "    if len(np.unique(labels)) < 2:\n",
    "        return float('nan')\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(labels, preds)\n",
    "    #filter for FPR <= max_fpr\n",
    "    mask = fpr <= max_fpr\n",
    "    fpr_filtered, tpr_filtered = fpr[mask], tpr[mask] \n",
    "      \n",
    "    if fpr_filtered.size == 0:\n",
    "        return 0.0\n",
    "\n",
    "    if fpr_filtered.max() < max_fpr:\n",
    "        idx = np.where(fpr <= max_fpr)[0][-1]\n",
    "        if idx + 1 < len(fpr):\n",
    "            x1, y1 = fpr[idx], tpr[idx]\n",
    "            x2, y2 = fpr[idx + 1], tpr[idx + 1]\n",
    "            tpr_interp = y1 + (y2 - y1) * (max_fpr - x1) / (x2 - x1) if (x2 - x1) > 0 else y1\n",
    "            fpr_filtered = np.append(fpr_filtered, max_fpr)\n",
    "            tpr_filtered = np.append(tpr_filtered, tpr_interp)\n",
    "            sort_idx = np.argsort(fpr_filtered)\n",
    "            fpr_filtered = fpr_filtered[sort_idx]\n",
    "            tpr_filtered = tpr_filtered[sort_idx]\n",
    "\n",
    "    return auc(fpr_filtered, tpr_filtered) / max_fpr if len(fpr_filtered) >= 2 else 0.0\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, labels, save_path, title=\"Confusion Matrix\"):\n",
    "    \"\"\"\n",
    "        Plots a confusion matrix for model evaluation\n",
    "    Args:\n",
    "        y_true (list or np.array): Ground truth labels.\n",
    "        y_pred (list or np.array): Predicted labels.\n",
    "        labels (list): A list of labels for the matrix axes (['Normal', 'Abnormal'])\n",
    "        title (str): Title for the plot\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "\n",
    "    print(f\"TP: {tp} | TN: {tn} | FP: {fp} | FN: {fn} | Precision: {precision:.4f} | Recall: {recall:.4f} | Specificity: {specificity:.4f}\")\n",
    "    plt.figure(figsize=(8,8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title(title)\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_path, \"Confusion Matrix.png\"))\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T17:46:12.413149Z",
     "iopub.status.busy": "2025-09-01T17:46:12.412912Z",
     "iopub.status.idle": "2025-09-01T17:46:12.494121Z",
     "shell.execute_reply": "2025-09-01T17:46:12.493305Z",
     "shell.execute_reply.started": "2025-09-01T17:46:12.413133Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using Device: {device}\" + (f\" - {torch.cuda.get_device_name(0)}\" if torch.cuda.is_available() else \"\"))\n",
    "\n",
    "FEATURES_DIR = os.path.abspath(r'F:\\CapStone\\DFCA\\data\\features\\-6_dB_features')\n",
    "\n",
    "CHECKPOINT_DIR = os.path.abspath(r'F:\\Capstone\\DFCA\\checkpoints\\CAFM')\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "print(f\"Checkpoints will be saved to: {CHECKPOINT_DIR}\")\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 50\n",
    "LR = 5e-5\n",
    "WEIGHT_DECAY = 1e-2\n",
    "PATIENCE=5\n",
    "\n",
    "print(f\"Learning Rate: {LR} | Weight decay: {WEIGHT_DECAY}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper, evaluate_model, train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T17:46:12.495454Z",
     "iopub.status.busy": "2025-09-01T17:46:12.495123Z",
     "iopub.status.idle": "2025-09-01T17:46:12.512855Z",
     "shell.execute_reply": "2025-09-01T17:46:12.512231Z",
     "shell.execute_reply.started": "2025-09-01T17:46:12.495423Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def _compute_primary_probs_and_loss_from_head(outputs, labels, criterion):\n",
    "    \"\"\"\n",
    "    Computes probabilities, predictions, and loss for a binary classifier head.\n",
    "    \"\"\"\n",
    "    logits = outputs.squeeze()\n",
    "    probs = torch.sigmoid(logits)\n",
    "    loss = criterion(logits, labels.float())\n",
    "    preds = (probs > 0.5).long()\n",
    "    return probs, preds, loss\n",
    "\n",
    "def evaluate_model(model, data_loader, criterion, phase=\"Evaluation\", device=device, threshold=0.5):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_labels, all_probs = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=phase):\n",
    "            # 1. Load data to the specified device\n",
    "            stft, cqt, labels= batch['stft'].to(device), batch['cqt'].to(device), batch['label'].to(device)\n",
    "            outputs = model(stft, cqt)\n",
    "\n",
    "            probs, _, loss = _compute_primary_probs_and_loss_from_head(outputs, labels, criterion)\n",
    "\n",
    "            running_loss += loss.item() * stft.size(0)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.detach().cpu().numpy())\n",
    "\n",
    "    # --- Metrics Calculation ---\n",
    "    avg_loss = running_loss / len(data_loader.dataset)\n",
    "    \n",
    "    # During validation, find the best F1-score and its threshold\n",
    "    best_threshold = threshold\n",
    "    if phase == \"Validation\":\n",
    "        best_f1 = 0\n",
    "        for thresh in np.arange(0.01, 1.0, 0.01):\n",
    "            preds_at_thresh = (np.array(all_probs) > thresh).astype(int)\n",
    "            f1_candidate = f1_score(all_labels, preds_at_thresh)\n",
    "            if f1_candidate > best_f1:\n",
    "                best_f1 = f1_candidate\n",
    "                best_threshold = thresh\n",
    "        print(f\"Optimal Threshold found: {best_threshold:.2f} (Best F1-score: {best_f1:.4f})\")\n",
    "\n",
    "    # Use the best threshold for final predictions\n",
    "    all_preds = (np.array(all_probs) > best_threshold).astype(int)\n",
    "    \n",
    "    # Calculate all metrics\n",
    "    auc_score = roc_auc_score(all_labels, all_probs) if len(np.unique(all_labels)) > 1 else float('nan')\n",
    "    acc_score = accuracy_score(all_labels, all_preds)\n",
    "    bacc_score = balanced_accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "    print(f\"{phase} -> Loss: {avg_loss:.4f} | AUC: {auc_score:.4f} | ACC: {acc_score:.4f} | BACC: {bacc_score:.4f} | F1: {f1:.4f}\")\n",
    "    print(f\"Prediction Distribution: {dict(Counter(all_preds))}\")\n",
    "\n",
    "    return avg_loss, auc_score, acc_score, bacc_score, f1, all_labels, all_probs, best_threshold\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, model_save_path, device=device, save_plots=True, patience=5):\n",
    "    best_val_auc = -np.inf\n",
    "    best_val_loss = np.inf\n",
    "    best_val_bacc = -np.inf\n",
    "    best_threshold = 0.5\n",
    "    patience_counter = 0\n",
    "\n",
    "    train_losses, val_losses = [],[]\n",
    "    train_accs, val_accs = [], []\n",
    "    train_baccs, val_baccs = [], []\n",
    "    train_aucs, val_aucs = [], []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        all_labels, all_probs, all_preds = [], [], []\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=\"Train\"):\n",
    "            stft, cqt, labels = batch['stft'].to(device), batch['cqt'].to(device), batch['label'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            logits = model(stft, cqt)\n",
    "\n",
    "            probs, preds, loss = _compute_primary_probs_and_loss_from_head(logits, labels, criterion)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * stft.size(0)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.detach().cpu().numpy())\n",
    "            all_preds.extend(preds.detach().cpu().numpy())\n",
    "\n",
    "        # --- End of Epoch: Calculate Training Metrics ---\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_auc = roc_auc_score(all_labels, all_probs)\n",
    "        epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "        epoch_bacc = balanced_accuracy_score(all_labels, all_preds)\n",
    "\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_aucs.append(epoch_auc)\n",
    "        train_accs.append(epoch_acc)\n",
    "        train_baccs.append(epoch_bacc)\n",
    "        \n",
    "        print(f\"Train -> Loss: {epoch_loss:.4f} | AUC: {epoch_auc:.4f} | ACC: {epoch_acc:.4f} | BACC: {epoch_bacc:.4f}\")\n",
    "\n",
    "        # --- Validation Step ---\n",
    "        val_loss, val_auc, val_acc, val_bacc, _, _, _, current_optimal_threshold = evaluate_model(\n",
    "            model, val_loader, criterion, phase=\"Validation\", device=device, threshold=best_threshold # type: ignore\n",
    "        )\n",
    "\n",
    "        val_losses.append(val_loss)\n",
    "        val_aucs.append(val_auc)\n",
    "        val_accs.append(val_acc)\n",
    "        val_baccs.append(val_bacc)\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        if val_bacc > best_val_bacc:\n",
    "            best_val_bacc = val_bacc\n",
    "            patience_counter = 0\n",
    "            bacc_path = model_save_path.replace(\".pth\", \"_best_bacc.pth\")\n",
    "            torch.save(model.state_dict(), bacc_path)\n",
    "            print(f\"Saved Best-BACC model to {bacc_path} (val_bacc improved to {best_val_bacc:.4f}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"Val BACC {val_bacc:.4f} did not improve from {best_val_bacc:.4f}. Patience: {patience_counter}/{patience}\")\n",
    "        \n",
    "        # Save by best loss\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            loss_path = model_save_path.replace(\".pth\", \"_best_loss.pth\")\n",
    "            torch.save(model.state_dict(), loss_path)\n",
    "            print(f\"Saved Best-Loss model to {loss_path} (val_loss improved to {best_val_loss:.4f})\")\n",
    "\n",
    "        # Save by best AUC\n",
    "        if not np.isnan(val_auc) and val_auc > best_val_auc:\n",
    "            best_val_auc = val_auc\n",
    "            best_threshold = current_optimal_threshold\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            print(f\"Saved Best-AUC model to {model_save_path} (val_auc improved to {best_val_auc:.4f})\")\n",
    "        else:\n",
    "            print(f\"Val AUC {val_auc:.4f} did not improve from best {best_val_auc:.4f}\")\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "            break\n",
    "    \n",
    "    # Plotting training history\n",
    "    if save_plots:\n",
    "        epochs = range(1, len(train_losses)+ 1)\n",
    "        plt.figure(figsize=(18, 5))\n",
    "        \n",
    "        plt.subplot(1, 4, 1)\n",
    "        plt.plot(epochs, train_losses, label='Train Loss')\n",
    "        plt.plot(epochs, val_losses, label='Val Loss')\n",
    "        plt.title('Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        plt.subplot(1, 4, 2)\n",
    "        plt.plot(epochs, train_aucs, label='Train AUC')\n",
    "        plt.plot(epochs, val_aucs, label='Val AUC')\n",
    "        plt.title('AUC')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.subplot(1, 4, 3)\n",
    "        plt.plot(epochs, train_accs, label='Train Accuracy')\n",
    "        plt.plot(epochs, val_accs, label='Val Accuracy')\n",
    "        plt.title('Accuracy')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        plt.subplot(1, 4, 4)\n",
    "        plt.plot(epochs, train_baccs, label='Train BACC')\n",
    "        plt.plot(epochs, val_baccs, label='Val BACC')\n",
    "        plt.title('Balanced Accuracy')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(os.path.dirname(model_save_path), \"training_summary.png\"))\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "    return best_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T17:46:12.513794Z",
     "iopub.status.busy": "2025-09-01T17:46:12.513552Z",
     "iopub.status.idle": "2025-09-01T18:04:51.233118Z",
     "shell.execute_reply": "2025-09-01T18:04:51.232314Z",
     "shell.execute_reply.started": "2025-09-01T17:46:12.513778Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # --- Configuration ---\n",
    "    SEED = 42\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # --- Data Transformations ---\n",
    "    train_transforms = ComposeT([\n",
    "        ToTensor(),\n",
    "        SpecTimePitchWarp(max_time_scale=1.1, max_freq_scale=1.1),\n",
    "        SpecAugment(freq_mask_param=2, time_mask_param=2, n_freq_masks=1, n_time_masks=1),\n",
    "    ])\n",
    "    no_transform = ComposeT([\n",
    "        ToTensor()\n",
    "    ])\n",
    "    \n",
    "    # --- Dataset Loading ---\n",
    "    print(\"Loading datasets for CQT spectrograms...\")\n",
    "    # Base paired dataset\n",
    "    base_dataset = PairedSpectrogramDataset(FEATURES_DIR, transform=None)\n",
    "    all_labels = [int(x) for x in base_dataset.labels]\n",
    "\n",
    "    \n",
    "    idxs = list(range(len(base_dataset)))\n",
    "    train_idx, temp_idx = train_test_split(idxs, test_size=0.3, stratify=all_labels, random_state=42)\n",
    "    val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, stratify=[all_labels[i] for i in temp_idx], random_state=42)\n",
    "\n",
    "    train_base = PairedSpectrogramDataset(FEATURES_DIR, transform=train_transforms)\n",
    "    val_base   = PairedSpectrogramDataset(FEATURES_DIR, transform=no_transform)\n",
    "    test_base  = PairedSpectrogramDataset(FEATURES_DIR, transform=no_transform)\n",
    "        \n",
    "    train_set = Subset(train_base, train_idx)\n",
    "    val_set   = Subset(val_base,   val_idx)\n",
    "    test_set  = Subset(test_base,  test_idx)\n",
    "\n",
    "    # --- Data Loaders ---\n",
    "    train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, drop_last=True)\n",
    "    val_loader   = DataLoader(val_set,   batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "    test_loader  = DataLoader(test_set,  batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "    print(f\"Split sizes => Train: {len(train_set)}, Val: {len(val_set)}, Test: {len(test_set)}\")\n",
    "    print(\"Label Distribution (Train):\", Counter([int(base_dataset[i]['label']) for i in train_idx]))\n",
    "    print(\"Label Distribution (Validation):\", Counter([int(base_dataset[i]['label']) for i in val_idx]))\n",
    "    print(\"Label Distribution (Test):\", Counter([int(base_dataset[i]['label']) for i in test_idx]))\n",
    "\n",
    "    # --- Model, Criterion, and Optimizer Setup ---\n",
    "    head = AnomalyScorer(in_dim=256, dropout=0.4, mode='classifier-1')\n",
    "    model = FusedModel(\n",
    "        stft_dim=512, cqt_dim=320, fusion_dim=256,\n",
    "        head=head\n",
    "    ).to(device)\n",
    "\n",
    "    # Use weighted Binary Cross-Entropy loss for imbalanced data\n",
    "    pos_count = sum(all_labels); neg_count = len(all_labels) - pos_count\n",
    "    pos_weight = torch.tensor([neg_count / (pos_count + 1e-8)], dtype=torch.float32).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    print(f\"\\nUsing BCEWithLogitsLoss with pos_weight: {pos_weight.item():.2f}\")\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=NUM_EPOCHS, eta_min=1e-6)\n",
    "\n",
    "    model_path = os.path.join(CHECKPOINT_DIR, \"best_model.pth\")\n",
    "    os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "\n",
    "    # --- Training ---\n",
    "    print(\"\\nStarting model training...\")\n",
    "    best_threshold = train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        num_epochs=NUM_EPOCHS,\n",
    "        model_save_path=model_path,\n",
    "        device=device,\n",
    "        save_plots=True,\n",
    "        patience=PATIENCE\n",
    "    )\n",
    "    \n",
    "    # --- Final Test Evaluation ---\n",
    "    print(\"\\n--- Final Test Evaluation ---\")\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "    # Evaluate using the best threshold found during validation\n",
    "    print(f\"Evaluating test set with optimal threshold: {best_threshold:.2f}\")\n",
    "    \n",
    "    # The simplified evaluate_model now returns the f1 score directly\n",
    "    _, test_auc, test_acc, test_bacc, test_f1, all_labels_test, all_probs_test, _ = evaluate_model(\n",
    "        model=model, data_loader=test_loader, criterion=criterion, phase=\"Test\", device=device, threshold=best_threshold\n",
    "    )\n",
    "    \n",
    "    # We must set the threshold for the test evaluation predictions.\n",
    "    # The new evaluate_model does not take threshold as an argument, so we apply it manually for the final report.\n",
    "    all_preds_test = (np.array(all_probs_test) > best_threshold).astype(int)\n",
    "    final_acc = accuracy_score(all_labels_test, all_preds_test)\n",
    "    final_bacc = balanced_accuracy_score(all_labels_test, all_preds_test)\n",
    "    final_f1 = f1_score(all_labels_test, all_preds_test)\n",
    "    final_pauc = calculate_pAUC(labels=all_labels_test, preds=all_probs_test, max_fpr=0.2)\n",
    "\n",
    "    print(f\"\\nFinal Test Metrics (Threshold = {best_threshold:.2f}):\")\n",
    "    print(f\"  -> Accuracy (ACC)         : {final_acc:.4f}\")\n",
    "    print(f\"  -> Balanced Accuracy (BACC): {final_bacc:.4f}\")\n",
    "    print(f\"  -> AUC                    : {test_auc:.4f}\")\n",
    "    print(f\"  -> pAUC (FPR<=0.2)        : {final_pauc:.4f}\")\n",
    "    print(f\"  -> F1-Score               : {final_f1:.4f}\")\n",
    "\n",
    "    # --- Plotting ---\n",
    "    # ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y_true=all_labels_test, y_score=all_probs_test)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.plot(fpr, tpr, lw=2, label=f\"AUC = {test_auc:.4f}\")\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=1, color='gray')\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"Test ROC With Optimal Threshold\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(CHECKPOINT_DIR, \"roc_test_optimal.png\"))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    class_labels = [\"Normal\", \"Abnormal\"]\n",
    "    plot_confusion_matrix(y_true=all_labels_test, y_pred=all_preds_test, labels=class_labels, save_path=CHECKPOINT_DIR, title=\"Test Set Confusion Matrix\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
